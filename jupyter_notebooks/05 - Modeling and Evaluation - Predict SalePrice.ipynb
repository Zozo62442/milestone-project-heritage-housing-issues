{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a classification model to predict if a prospect will churn or not.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "* Instructions on which variables to use for data cleaning and feature engineering. They are found in each respective notebook.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Train set (features and target)\n",
        "* Test set (features and target)\n",
        "* Data cleaning and Feature Engineering pipeline\n",
        "* Modeling pipeline\n",
        "* Feature importance plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory set to:\n",
            "/workspaces/milestone-project-heritage-housing-issues\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "project_root = \"/workspaces/milestone-project-heritage-housing-issues\"\n",
        "os.chdir(project_root)\n",
        "\n",
        "print(\"Current working directory set to:\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Step 1: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Xk7DU_ekbtX8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 22)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>...</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "\n",
              "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
              "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
              "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
              "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
              "\n",
              "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
              "0       196.0           61            5            7          856       2003   \n",
              "1         0.0            0            8            6         1262       1976   \n",
              "2       162.0           42            5            7          920       2001   \n",
              "\n",
              "   YearRemodAdd  SalePrice  \n",
              "0          2003     208500  \n",
              "1          1976     181500  \n",
              "2          2002     223500  \n",
              "\n",
              "[3 rows x 22 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/cleaned/house_prices_cleaned.csv\")\n",
        "      .drop(labels=['EnclosedPorch', 'WoodDeckSF'], axis=1)  \n",
        "  )\n",
        "\n",
        "print(df.shape)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofil7xTpm6l9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Step 2: ML Pipeline with all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfCsXhBYVBJw"
      },
      "source": [
        "## ML pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "C6keis6ao8LA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
              "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
              "                                variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
              "                                           &#x27;GarageFinish&#x27;, &#x27;KitchenQual&#x27;])),\n",
              "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
              "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
              "                                          selection_method=&#x27;variance&#x27;,\n",
              "                                          threshold=0.6))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;OrdinalCategoricalEncoder&#x27;,\n",
              "                 OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
              "                                variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
              "                                           &#x27;GarageFinish&#x27;, &#x27;KitchenQual&#x27;])),\n",
              "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
              "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
              "                                          selection_method=&#x27;variance&#x27;,\n",
              "                                          threshold=0.6))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(encoding_method=&#x27;arbitrary&#x27;,\n",
              "               variables=[&#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;GarageFinish&#x27;,\n",
              "                          &#x27;KitchenQual&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
              "                         threshold=0.6)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('OrdinalCategoricalEncoder',\n",
              "                 OrdinalEncoder(encoding_method='arbitrary',\n",
              "                                variables=['BsmtExposure', 'BsmtFinType1',\n",
              "                                           'GarageFinish', 'KitchenQual'])),\n",
              "                ('SmartCorrelatedSelection',\n",
              "                 SmartCorrelatedSelection(method='spearman',\n",
              "                                          selection_method='variance',\n",
              "                                          threshold=0.6))])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'])),\n",
        "\n",
        "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
        "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n",
        "\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_7BXNYMULrf"
      },
      "source": [
        "## ML Pipeline for Modelling and Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PYR4hz6-Ldvo"
      },
      "outputs": [],
      "source": [
        "# Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def PipelineClf(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feat_selection\", SelectFromModel(model)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM_hrtfjLj85"
      },
      "source": [
        "Custom Class for Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NpTcVDtQ5RMc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUcOp83jy0QG"
      },
      "source": [
        "## Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0vqzNI2zF1sZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 21) (1168,) (292, 21) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zBysp0tyqR2"
      },
      "source": [
        "## Handle Target Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns with missing values:\n",
            "\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values per column\n",
        "missing_counts = df.isnull().sum()\n",
        "missing_counts = missing_counts[missing_counts > 0]\n",
        "\n",
        "# Show the columns that have missing values and how many\n",
        "print(\"Columns with missing values:\\n\")\n",
        "print(missing_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify and convert categorical columns\n",
        "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Also include any known categorical columns that might be read as float (e.g., ordinal categories)\n",
        "additional_categoricals = ['GarageFinish', 'BsmtExposure', 'KitchenQual', 'BsmtFinType1'] \n",
        "for col in additional_categoricals:\n",
        "    if col in X_train.columns:\n",
        "        categorical_cols.append(col)\n",
        "\n",
        "# Remove duplicates\n",
        "categorical_cols = list(set(categorical_cols))\n",
        "\n",
        "# Convert dtype\n",
        "X_train[categorical_cols] = X_train[categorical_cols].astype('category')\n",
        "X_test[categorical_cols] = X_test[categorical_cols].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MsQRvnn1GI_d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 17) (1168,) (292, 17) (292,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n"
          ]
        }
      ],
      "source": [
        "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
        "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
        "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuq3902arZAz"
      },
      "source": [
        "Check Train Set Target distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "I28ACrp-rPgF"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHuCAYAAABqGo2uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACPwUlEQVR4nOzdd3gU5fo//vfWJLub3nuDhACpdAggCNKVqggIevRjw4MKNo79fI+ix4qix4KgHDkoSm8WkKKAShWSQKgpENJ73c1mf3/wm3F3s5tsQgIOvF/XxUV2dmb2mfbMPTPPc4/MZDKZQERERCRR8mtdACIiIqIrwWCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCG6Ao988wzGD58+LUuBnWyCxcuIDY2FmvXru3031q7di1iY2Nx4cIFcdjw4cPxwAMPdPpvA8Bvv/2G2NhY/Pbbb1fl94iulPJaF4Cos8TGxjo03ooVK9CvX79OLk3bXLhwAR988AEOHDiAgoICuLm5ISIiAv369cO8efPaPL/du3fj2LFj+Pvf/97ieGvXrsXChQtbnV9wcDB++umnNpejM61cuRIuLi6YPHmyQ+Ob7x8KhQI6nQ4hISFISUnB9OnT0aVLl2tSrqvpr1w2oraQ8d1MdL3asGFDs8979+7Fv//9b4vhgwYNgo+PT7t/x2AwwGQyQa1Wt3se5rKzszF16lQ4OTlhypQpCAkJQWFhITIyMrBnzx4cP368zfP85z//iZUrVyIzM7PF8XJzc3H48GGLYc899xwSEhJw++23i8O0Wi1GjBjR5nJ0pvHjx8PT0xP//e9/HRo/NjYWgwYNwm233QaTyYTq6mqcPHkS3333Herq6vDEE0/gnnvuEcc3mUzQ6/VQKpVQKBSdVi4AMBqNaGxshFqthkwmA3D5zkzXrl3x8ccfOzyf9patqakJBoMBKpUKcjlv4NNfH+/M0HXrtttus/j8xx9/YO/evc2GW6urq4OLi4vDv6NSqdpVPns+//xz1NbWYv369QgODrb4rqSkpEN/y1poaChCQ0Mthr300ksIDQ1tdb05oqGh4S91goyIiGi2XAsWLMBDDz2E1157DVFRURg6dCgAQCaTwcnJqVPLU1tbC41GA4VC0aaAqaPJ5fJOX1aijvTXqFGIrpG77roL48ePR1paGmbOnInExES8/fbbAIDt27fj/vvvR2pqKnr27IkRI0bggw8+gNFotJiHdZsZoW3FZ599hq+//hojRoxAz549MWXKFBw7dqzVMuXk5MDf379ZIAMA3t7ezYbt3r0bM2bMQFJSEpKTk3H//ffj9OnTFuVbuXIlgMt3I4R/7VVeXo7XX38dEyZMQHJyMlJSUnDffffh5MmTFuMJ7S62bNmCd955B4MHD0ZiYiKqq6sBANu2bcPYsWMRHx+P8ePH48cff7TZ/qipqQmff/45xo0bh/j4eAwcOBAvvPACKioqxHGGDx+O06dP4/fffxeX76677mrX8nl6euLtt9+GUqnEf/7zH3G4rTYzRUVFWLhwIYYMGYKePXsiNTUVDz30kNjWpaVyCe1ifv/9d7z00ksYMGCAGDjZajMj+OWXX3DbbbchPj4eY8eOxQ8//GDx/fvvv29z+1rPs6Wy2Wszs23bNkyePBkJCQno168fnnjiCRQUFFiM88wzzyA5ORkFBQV4+OGHkZycjP79++P1119vduwQdRTemaEbXnl5Of7v//4P48aNw6233ioGDOvWrYNGo8E999wDjUaDX3/9Fe+99x6qq6vx9NNPtzrfzZs3o6amBnfccQdkMhmWLl2Kv//979i+fXuLd3OCg4Oxf/9+7N+/HwMGDGjxN9avX49nnnkGqampeOKJJ1BXV4dVq1ZhxowZWLduHUJCQnDHHXegsLDQ5iO29sjNzcX27dsxevRohISEoLi4GF9//TVmzZqFLVu2wN/f32L8Dz/8ECqVCvfeey/0ej1UKhV27dqFxx9/HDExMViwYAEqKirw7LPPNpsWAF544QWsW7cOkydPxl133YULFy5g5cqVyMjIwKpVq6BSqfCPf/wD/+///T9oNBo8+OCDAHBFjw6DgoLQp08f/Pbbb6iuroZOp7M53t///necOXMGs2bNQnBwMEpLS7F3715cunQJISEhDpXr5ZdfhpeXF+bOnYva2toWy5WVlYXHH38c06dPx6RJk7BmzRo8+uijWLp0KQYNGtSmZWzrOhPaU8XHx2P+/PkoKSnBihUrcPjwYaxfvx5ubm7iuEajEffeey8SEhLw1FNPYf/+/Vi2bBlCQ0MxY8aMNpWTyCEmohvEyy+/bIqJibEYNmvWLFNMTIxp1apVzcavq6trNuz55583JSYmmhoaGsRhTz/9tGnYsGHi59zcXFNMTIypb9++pvLycnH49u3bTTExMaaffvqpxXKeOnXKlJCQYIqJiTHddtttpn/961+mH3/80VRbW2sxXnV1tal3796m5557zmJ4UVGRqVevXhbDbS27o5KSkkxPP/20+LmhocFkNBotxsnNzTX17NnTtGTJEnHYr7/+aoqJiTHdfPPNzdbl+PHjTUOGDDFVV1eLw3777TdTTEyMxbo8cOCAKSYmxrRx40aL6ffs2dNs+Lhx40yzZs1yeLliYmJML7/8st3v//Wvf5liYmJMJ06cEJcxJibGtGbNGpPJZDJVVFSYYmJiTEuXLm3xd+yVa82aNaaYmBjTnXfeaWpsbLT5XW5urjhs2LBhppiYGNP3338vDquqqjINGjTINHHiRHHYe++9Z3Nb25qnvbIJ2+7XX381mUwmk16vNw0YMMA0fvx4U319vTjezp07TTExMabFixeLw55++mlTTEyMxb5gMplMEydONE2aNKn5CiLqAHzMRDc8tVptszeHs7Oz+Hd1dTVKS0vRu3dv1NXV4dy5c63Od+zYsXB3dxc/9+7dG8DlOxst6dq1K9avX49bb70VFy9exIoVKzB37lwMHDgQq1evFsfbt28fKisrMW7cOJSWlor/5HI5EhMTO61brVqtFtu8GI1GlJWVQaPRIDIyEhkZGc3GnzhxosW6LCgowKlTpzBx4kRotVpxeN++fRETE2Mx7XfffQdXV1cMGjTIYhl79OgBjUbTqV2HNRoNAKCmpsbm987OzlCpVPj9998tHnm11e233+5w+xg/Pz+MHDlS/KzT6TBx4kRkZGSgqKio3WVoTVpaGkpKSnDnnXdatKW56aabEBUVhV27djWb5s4777T43KtXL5uPzYg6Ah8z0Q3P39/fZk+k06dP491338Wvv/4qtvMQVFVVtTrfwMBAi89CYFNZWdnqtJGRkXjjjTdgNBpx5swZ7Nq1C0uXLsXzzz+PkJAQDBw4EFlZWQCAOXPm2JyHvUcjV6qpqQkrVqzA//73P1y4cMGiHYSHh0ez8UNCQiw+5+XlAQDCwsKajRseHm4REGVnZ6Oqqsru47bObBAtPPIxD7jMqdVqPPHEE3j99dcxaNAgJCYm4qabbsLEiRPh6+vr8O9Yr5+WhIeHi72bBBEREQCAixcvtul320LYZpGRkc2+i4qKwqFDhyyGOTk5wcvLy2KYu7v7FQV9RC1hMEM3PPO7BoLKykrMmjULOp0O8+bNQ1hYGJycnJCeno4333wTTU1Nrc7X3tW2qQ3ZEBQKhdg4MykpCbNnz8amTZswcOBAcT7//ve/bZ7EOqs3zEcffYTFixdjypQpePTRR+Hu7g65XI5XX33V5rLZWr+Oampqgre3N958802b31ufMDvS6dOnoVAoWgw27r77bgwfPhzbt2/HL7/8gsWLF+OTTz7BF198ge7duzv0Ox3da8g62BFczca317InFt2YGMwQ2fD777+jvLwcS5YsQZ8+fcTh1/I2ec+ePQEAhYWFACB2ofb29sbAgQNbnNbeCa49vv/+e/Tr1w+vvvqqxfDKykp4enq2On1QUBCAy722rGVnZ1t8DgsLw/79+5GSktJqUNSRy5iXl4cDBw4gKSmp1TtcYWFh+Nvf/oa//e1vyMrKwsSJE7Fs2TIxAOvIcmVnZ8NkMlnMU7hDJ/R+ExriVlZWWjTKFe6umHO0bMI2O3/+fLO7ZOfPnxe/J7pW2GaGyAahTYj5nQa9Xo///e9/nf7bBw8ehMFgaDZ89+7dAP681T948GDodDp8/PHHNscvLS0V/xby5jjyiKs1CoWi2R2Ybdu2Neuia4+/vz9iYmKwfv16i/Yov//+O06dOmUx7pgxY2A0GvHhhx82m09jY6PF8ri4uHTI8pWXl2P+/PkwGo1iLx9b6urq0NDQYDEsLCwMWq0Wer2+w8sFXA5kf/zxR/FzdXU11q9fj7i4OPHunPD47sCBA+J4Qt4ia46WrWfPnvD29sZXX31lsWy7d+/G2bNncdNNN7VziYg6Bu/MENmQnJwMd3d3PPPMM7jrrrsgk8mwYcOGNj0iaq9PP/0U6enpGDlypJgvJCMjA+vXr4eHh4fYRkan0+Gll17CU089hcmTJ2Ps2LHw8vJCXl4edu/ejZSUFLzwwgsAgB49egAA/vWvfyE1NRUKhQLjxo1rV/luuukmfPDBB1i4cCGSk5Nx6tQpbNq0qVmyvZY8/vjjePjhh3HnnXdi8uTJqKysxMqVKxETE2MR4PTt2xd33HEHPv74Y5w4cQKDBg2CSqVCVlYWvvvuOzz77LMYPXq0uIyrVq3Chx9+iPDwcHh5ebXatT0rK0vcrjU1NWIG4NraWjzzzDMYMmRIi9PefffdGD16NLp06QKFQoHt27ejuLjYYt22p1z2RERE4Nlnn8Xx48fh7e2NNWvWoKSkBIsWLRLHGTRoEIKCgvDss8/i3LlzUCgUWLNmDTw9PZvdnXG0bCqVCk888QQWLlyIWbNmYdy4cWLX7ODgYNx9993tWh6ijsJghsgGT09PfPTRR3j99dfx7rvvws3NDbfeeisGDBiAe++9t1N/+4EHHsDmzZtx4MABbNq0CfX19fD19cW4cePw8MMPWwQNEyZMgJ+fHz755BN89tln0Ov18Pf3R+/evS16aN1yyy246667sGXLFmzcuBEmk6ndwcyDDz6Iuro6bNq0CVu3bkX37t3x8ccf46233nJ4HsOHD8fbb7+N999/H2+99RYiIiKwaNEirF+/3iLhH3D5VQw9e/bEV199hXfeeQcKhQLBwcG49dZbkZKSIo43d+5c5OXlYenSpaipqUHfvn1bDRr27t2LvXv3Qi6Xi+9mmjhxIu64445W380UEBCAcePGYf/+/di4cSMUCgWioqLw7rvvYtSoUVdULnsiIiLw/PPP49///jfOnz+PkJAQMSGhQKVSYcmSJXj55ZexePFi+Pr6Ys6cOXBzc2v23q22lG3y5MlwdnbGp59+ijfffBMajQYjRozAk08+afE4i+ha4LuZiOgv47bbboOXlxeWL19+rYtCRBLCNjNEdNUZDAY0NjZaDPvtt99w8uRJ9O3b9xqVioikio+ZiOiqKygowD333INbb70Vfn5+OHfuHL766iv4+vpi+vTp17p4RCQxDGaI6Kpzd3dHjx498M0336C0tBQajQZDhw7FE0884VD3biIic2wzQ0RERJLGNjNEREQkaQxmiIiISNKuizYzTU1NaGxshFwu79DU4URERNR5TCYTmpqaoFQqxczr7XFdBDONjY04fvz4tS4GERERtUN8fDzUanW7p78uHjNdSTRHRERE19aVnseviyiAj5aIiIik60rP49dFMENEREQ3LgYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJO26Cmb8/f2hVCqvdTGIiIjoKrqugpnAwECoVKprXQwiIiK6iq6rYIaIiIhuPAxmiIiISNIYzBAREZGktbm17IEDB/DZZ58hLS0NRUVF+OCDDzBixAjx+9jYWJvTPfnkk7jvvvtsfvf+++9jyZIlFsMiIyPx3XfftbV4REREdINpczBTW1uL2NhYTJkyBY888kiz73/55ReLz3v27MGzzz6LUaNGtTjfrl27Yvny5eJnhULR1qIRERHRDajNwczQoUMxdOhQu9/7+vpafN6xYwf69euH0NDQFuerUCiaTUtERETUmk5tM1NcXIzdu3dj6tSprY6bnZ2N1NRU3HzzzViwYAHy8vI6s2hERER0nejUDHPr1q2DVqvFLbfc0uJ4CQkJWLRoESIjI8V2ODNnzsSmTZug0+k6s4hEREQkcZ0azKxZswYTJkyAk5NTi+OZP7bq1q0bEhMTMWzYMGzbtg3Tpk3rzCISERGRxHXaY6aDBw/i/Pnz7QpG3NzcEBERgZycnE4oGREREV1POi2Y+fbbb9GjRw9069atzdPW1NQgNzeXDYKJiIioVW0OZmpqanDixAmcOHECAHDhwgWcOHHCosFudXU1vvvuO7t3ZebMmYMvv/xS/Pz666/j999/x4ULF3D48GE88sgjkMvlGD9+fFuLR0RERDeYNreZSUtLw+zZs8XPixYtAgBMmjQJr732GgBgy5YtMJlMdoOR3NxclJWViZ/z8/Mxf/58lJeXw8vLC7169cLq1avh5eXV1uIRERHRDUZmMplM17oQV8poNOLo0aNISkpCZmYm6urqrnWRiIiIyEFJSUlXlCyX72YiIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaW0OZg4cOIAHH3wQqampiI2Nxfbt2y2+f+aZZxAbG2vx79577211vitXrsTw4cMRHx+PadOm4dixY20tGhEREd2A2hzM1NbWIjY2Fi+++KLdcQYPHoxffvlF/Pf222+3OM+tW7di0aJFmDt3LtatW4du3brh3nvvRUlJSVuLR0RERDcYZVsnGDp0KIYOHdriOGq1Gr6+vg7Pc/ny5bj99tsxZcoUAMDLL7+MXbt2Yc2aNbj//vvbWkQiIiK6gXRKm5nff/8dAwYMwKhRo/Diiy+irKzM7rh6vR7p6ekYOHDgn4WSyzFw4EAcOXKkM4pHRERE15E235lpzeDBgzFy5EiEhIQgNzcXb7/9Nv7v//4PX3/9NRQKRbPxy8rKYDQa4e3tbTHc29sb586d6+jiERER0XWmw4OZcePGiX8LDYBHjBgh3q0hIiIi6kid3jU7NDQUnp6eyM7Otvm9p6cnFApFs8a+JSUl8PHx6eziERERkcR1ejCTn5+P8vJyuw2C1Wo1evTogf3794vDmpqasH//fiQnJ3d28YiIiEji2vyYqaamBjk5OeLnCxcu4MSJE3B3d4e7uzuWLFmCUaNGwcfHB7m5uXjjjTcQHh6OwYMHi9PMmTMHI0eOxKxZswAA99xzD55++mn07NkTCQkJ+OKLL1BXV4fJkyd3wCISERHR9azNwUxaWhpmz54tfl60aBEAYNKkSXjppZdw6tQprF+/HlVVVfDz88OgQYPw6KOPQq1Wi9Pk5uZa9HAaO3YsSktL8d5776GoqAhxcXFYunQpHzMRERFRq2Qmk8l0rQtxpYxGI44ePYqkpCRkZmairq7uWheJiIiIHJSUlGSzx7Oj+G4mIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJu+6CGV9fXyiVymtdDCIiIrpKrstgRqVSXetiEBER0VVy3QUzREREdGNhMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjS2hzMHDhwAA8++CBSU1MRGxuL7du3i98ZDAa88cYbmDBhApKSkpCamoqnnnoKBQUFLc7z/fffR2xsrMW/0aNHt31piIiI6IajbOsEtbW1iI2NxZQpU/DII49YfFdfX4+MjAw89NBD6NatGyorK/HKK6/goYcewtq1a1ucb9euXbF8+XLxs0KhaGvRiIiI6AbU5mBm6NChGDp0qM3vXF1dLQISAHj++ecxbdo05OXlISgoyO58FQoFfH1921ocIiIiusG1OZhpq+rqashkMri5ubU4XnZ2NlJTU+Hk5ISkpCQsWLCgxeCHiIiICOjkYKahoQFvvvkmxo0bB51OZ3e8hIQELFq0CJGRkSgqKsIHH3yAmTNnYtOmTS1OR0RERNRpwYzBYMCjjz4Kk8mEl19+ucVxzR9bdevWDYmJiRg2bBi2bduGadOmdVYRiYiI6DrQKcGMwWDAY489hry8PHzxxRdtvrvi5uaGiIgI5OTkdEbxiIiI6DrS4cGMEMhkZ2djxYoV8PT0bPM8ampqkJubywbBRERE1Ko2BzM1NTUWd0wuXLiAEydOwN3dHb6+vpg3bx4yMjLw8ccfw2g0oqioCADg7u4OtVoNAJgzZw5GjhyJWbNmAQBef/11DBs2DEFBQSgsLMT7778PuVyO8ePHd8QyEhER0XWszcFMWloaZs+eLX5etGgRAGDSpEl45JFH8NNPPwEAbrvtNovpVqxYgX79+gEAcnNzUVZWJn6Xn5+P+fPno7y8HF5eXujVqxdWr14NLy+vti8RERER3VBkJpPJdK0LcaWMRiOOHj2KpKQkKBQKZGRkoK6u7loXi4iIiBwgnL/bi+9mIiIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKStOsymFEqlde6CERERHSVXHfBjLHJhKjoaKhUqmtdFCIiIroKrrtgRiGXQalQ8O4MERHRDeK6C2aIiIjoxsJghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0toczBw4cAAPPvggUlNTERsbi+3bt1t8bzKZsHjxYqSmpiIhIQF33303srKyWp3vypUrMXz4cMTHx2PatGk4duxYW4tGREREN6A2BzO1tbWIjY3Fiy++aPP7Tz/9FP/973/x0ksvYfXq1XBxccG9996LhoYGu/PcunUrFi1ahLlz52LdunXo1q0b7r33XpSUlLS1eERERHSDaXMwM3ToUDz++OMYOXJks+9MJhNWrFiBhx56CCNGjEC3bt3w73//G4WFhc3u4Jhbvnw5br/9dkyZMgVdunTByy+/DGdnZ6xZs6atxSMiIqIbTIe2mblw4QKKioowcOBAcZirqysSExNx5MgRm9Po9Xqkp6dbTCOXyzFw4EC70zhCqVS2e1oiIiKSjg4NZoqKigAA3t7eFsO9vb1RXFxsc5qysjIYjcY2TdMaY5MJUdHRUKlU7ZqeiIiIpOO67M2kkMugVCh4d4aIiOgG0KHBjK+vLwA0a7hbUlICHx8fm9N4enpCoVC0aRoiIiIiQYcGMyEhIfD19cX+/fvFYdXV1fjjjz+QnJxscxq1Wo0ePXpYTNPU1IT9+/fbnYaIiIhI0ObnMDU1NcjJyRE/X7hwASdOnIC7uzuCgoIwe/Zs/Oc//0F4eDhCQkKwePFi+Pn5YcSIEeI0c+bMwciRIzFr1iwAwD333IOnn34aPXv2REJCAr744gvU1dVh8uTJHbCIREREdD1rczCTlpaG2bNni58XLVoEAJg0aRJee+01/N///R/q6urwwgsvoLKyEr169cLSpUvh5OQkTpObm4uysjLx89ixY1FaWor33nsPRUVFiIuLw9KlS/mYiYiIiFolM5lMpmtdiCtlNBpx9OhRJCUlQaFQiMMzMjJQV1d3DUtGRERErbE+f7fVddmbiYiIiG4cDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJu66DGaXyz5eCq1QqqFSqa1gaIiIi6gzK1keRJmOTCV26dEFZWRlMJhM8PL0AmJCRng6DwXCti0dEREQd5LoNZhRyGQAZvL29LYYrlUoGM0RERNeR6/oxExEREV3/GMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGnKa12Aq83Z2RkymQwGgwEGg+FaF4eIiIiu0A0VzBibTAiPiAQAyGBCWVkZDAYDCgoK0NjYeI1LR0RERO1xQwUzCrnM7JMM3t7eAIDS0lIGM0RERBLFNjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSevwBsDDhw/HxYsXmw2fMWMGXnzxxWbD165di4ULF1oMU6vVOH78eEcXjYiIiK5DHR7MfPvttzAajeLn06dP45577sHo0aPtTqPT6fDdd9+Jn2Uymd1xiYiIiMx1eDDj5eVl8fmTTz5BWFgY+vbta3camUwGX1/fji4KERER3QA6tc2MXq/Hxo0bMWXKlBbvttTW1mLYsGEYOnQoHnroIZw+fbozi0VERETXkU4NZrZv346qqipMmjTJ7jiRkZF49dVX8eGHH+KNN96AyWTC9OnTkZ+f35lFIyIioutEp2YAXrNmDYYMGQJ/f3+74yQnJyM5Odni89ixY/HVV1/hscce68ziERER0XWg0+7MXLx4Efv27cPUqVPbNJ1KpUJcXBxycnI6qWRERER0Pem0YGbt2rXw9vbGTTfd1KbpjEYjTp06xQbBRERE5JBOeczU1NSEtWvXYuLEiVAqLX/iqaeegr+/PxYsWAAAWLJkCZKSkhAeHo7Kykp89tlnyMvLw7Rp0zqjaERERHSd6ZRgZt++fcjLy8OUKVOafXfp0iXI5X/eEKqsrMTzzz+PoqIiuLu7o0ePHvjqq6/QpUuXzigaERERXWdkJpPJdK0LcaWMRiOOHj2KpKQkKBSKNk+fkZGBurq6TigZERERtaa9528B381EREREksZghoiIiCStU/PMSIVSqYRGowEAGAwGGAwGAJe7iQvDiIiI6K+JwQyAqOgu4usWZDChrKwMJpMJHp5eAEzISE9nQENERPQXxWAGgFJh/rRNBm9vb8vvlUoGM0RERH9RbDNDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJU17rAkiBs7MzGhsbYTAYxGEqlQoqlQoAYDAYLL4jIiKiq4fBTCuMTSaER0RCBhPKyspgNBohl8vh4ekFmUwGAJDBhJMnT6Kuru4al5aIiOjGw2CmFQq57P//SwZvb287Y8ng7OzMYIaIiOgaYJsZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREktbhwcz777+P2NhYi3+jR49ucZpt27Zh9OjRiI+Px4QJE7B79+6OLhYRERFdp5SdMdOuXbti+fLl4meFQmF33MOHD2PBggWYP38+hg0bhk2bNmHu3LlYu3YtYmJiOqN4REREdB3plMdMCoUCvr6+4j8vLy+7465YsQKDBw/Gfffdh+joaDz22GPo3r07vvzyy84oGhEREV1nOiWYyc7ORmpqKm6++WYsWLAAeXl5dsc9evQoBgwYYDEsNTUVR48e7YyidTqVSgWNRgONRgOVSuXQdy1NQ0RERC3r8MdMCQkJWLRoESIjI1FUVIQPPvgAM2fOxKZNm6DT6ZqNX1xcDB8fH4th3t7eKC4u7uiidSovLy+4ubnBw9MLMpkMACCDCWVlZTAajZDL5Ta/M5lMFsNNpiZkpKfDYDBcs2UhIiKSkg4PZoYOHSr+3a1bNyQmJmLYsGHYtm0bpk2b1tE/95fh4eFhY6gM3t7edqaw950CSqWSwQwREZGDOr1rtpubGyIiIpCTk2Pzex8fn2Z3YUpKSprdrSEiIiKypdODmZqaGuTm5sLX19fm90lJSfj1118thu3btw9JSUmdXTQiIiK6DnR4MPP666/j999/x4ULF3D48GE88sgjkMvlGD9+PADgqaeewltvvSWOP3v2bPz8889YtmwZzp49i/fffx9paWmYNWtWRxeNiIiIrkMd3mYmPz8f8+fPR3l5Oby8vNCrVy+sXr1a7J596dIlyOV/xlApKSl488038e677+Ltt99GREQEPvjgA+aYISIiIofITCaT6VoX4koZjUYcPXoUSUlJLSbok4qMjAzU1dVd62IQERFdFVd6/ua7mYiIiEjSGMwQERGRpDGYISIiIkljMENERESSxmCGiIiIJI3BDBEREUkagxkiIiKSNAYzREREJGkMZoiIiEjSGMwQERGRpDGYISIiIknr8BdNUsdRqVRQqVTiZ4PBAIPB0Ow7e8OtvyMiIroeMZj5CwoICEBTUxM8PL0gk8nE4TKYUFZWBpPJZPGdveEAYDI1ISM9nQENERFdtxjM/AV5eXnZ+UYGb2/vNgwHAAWUSiWDGSIium6xzQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJmvJaF4CuHpVKBZVKBQAwGAwwGAwtDr9a05gPtzU/IiKiljCYuQEEBASgqakJHp5ekMlkAAAZTCgrK4PJZLI53Gg0Qi6Xd/o01sMBwGRqQkZ6OgMaIiJyCIOZG4CXl5eNoTJ4e3u3YfjVnEYBpVLJYIaIiBzCNjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSevwBsAff/wxfvjhB5w7dw7Ozs5ITk7GE088gaioKLvTrF27FgsXLrQYplarcfz48Y4uHhEREV1nOjyY+f333zFz5kzEx8fDaDTi7bffxr333ostW7ZAo9HYnU6n0+G7774TP5t31SUiIiKyp8ODmc8++8zi82uvvYYBAwYgPT0dffr0sTudTCaDr69vRxeHiIiIrnOdnmemqqoKAODu7t7ieLW1tRg2bBiamprQvXt3zJ8/H127du3s4hEREZHEdWoD4KamJrz66qtISUlBTEyM3fEiIyPx6quv4sMPP8Qbb7wBk8mE6dOnIz8/vzOLR0RERNeBTr0z8/LLL+P06dP43//+1+J4ycnJSE5Otvg8duxYfPXVV3jsscc6s4hEREQkcZ0WzPzzn//Erl278OWXXyIgIKBN06pUKsTFxSEnJ6eTSkdERETXiw5/zGQymfDPf/4TP/74I7744guEhoa2eR5GoxGnTp1ig2AiIiJqVYffmXn55ZexefNmfPjhh9BqtSgqKgIAuLq6wtnZGQDw1FNPwd/fHwsWLAAALFmyBElJSQgPD0dlZSU+++wz5OXlYdq0aR1dPCIiIrrOdHgws2rVKgDAXXfdZTF80aJFmDx5MgDg0qVLkMv/vClUWVmJ559/HkVFRXB3d0ePHj3w1VdfoUuXLh1dPCIiIrrOyEwmk+laF+JKGY1GHD16FElJSVAoFNe6ONQBMjIyUFdXd62LQUREV8GVnr/5biYiIiKStE5Pmkd0JVQqFVQqFQDAYDDAYDA0G97Sd44Mv1rTXK0yExHdaBjM0F9SQEAAmpqa4OHpJb6nSwYTysrKYDKZLIa39F1rw41GI+RyeadPczXKfPLkST6aI6IbEtvMEF0nzp07h7KysmtdDCKiNmObGSIiIrqhMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkMZghIiIiSWMwQ0RERJLGYIaIiIgkjcEMERERSRqDGSIiIpI0BjNEREQkaQxmiIiISNIYzBAREZGkKa91AYioY6lUKqhUKgCAwWCAwWBo9TtHhl+taa60zFxOLqcUl1OKZe6I5dTr9WhsbMSVYjBDdJ3w8vKCm5sbPDy9IJPJAAAymFBWVgaj0Qi5XG7zO5PJ5NDwqzXNlZSZy8nllOJySrHMHbWcTcZGHDt2DFdKZjKZTFc8l2vMaDTi6NGjSEpKgkKhuNbFISIiIgd01PmbbWaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSNwQwRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJYzBDREREksZghoiIiCSt04KZlStXYvjw4YiPj8e0adNafcX3tm3bMHr0aMTHx2PChAnYvXt3ZxWNiIiIriOdEsxs3boVixYtwty5c7Fu3Tp069YN9957L0pKSmyOf/jwYSxYsABTp07F+vXrcfPNN2Pu3Lk4depUZxSPiIiIriOdEswsX74ct99+O6ZMmYIuXbrg5ZdfhrOzM9asWWNz/BUrVmDw4MG47777EB0djcceewzdu3fHl19+2RnFIyIioutIhwczer0e6enpGDhw4J8/Ipdj4MCBOHLkiM1pjh49igEDBlgMS01NxdGjRzu6eERERHSdUXb0DMvKymA0GuHt7W0x3NvbG+fOnbM5TXFxMXx8fJqNX1xc7NBvmkwmAIDRaGxHiYmIiOhaEM7bwnm8vTo8mLkWmpqaAADHjx+/xiUhIiKithLO4+3V4cGMp6cnFApFs8a+JSUlze6+CHx8fJrdhWlpfGtKpRLx8fGQy+WQyWTtKzgRERFdVSaTCU1NTVAqrywc6fBgRq1Wo0ePHti/fz9GjBgB4HLEtX//fsyaNcvmNElJSfj1119x9913i8P27duHpKQkh35TLpdDrVZfadGJiIhIgjqlN9M999yD1atXY926dTh79ixeeukl1NXVYfLkyQCAp556Cm+99ZY4/uzZs/Hzzz9j2bJlOHv2LN5//32kpaXZDX6IiIiIBJ3SZmbs2LEoLS3Fe++9h6KiIsTFxWHp0qXiY6NLly5BLv8zjkpJScGbb76Jd999F2+//TYiIiLwwQcfICYmpjOKR0RERNcRmelKmxATERERXUN8NxMRERFJGoMZIiIikjQGM0RERCRpDGaIiIhI0hjMEBERkaQxmCEiIiJJuy7ezdRWx44dw5EjR8RXKNTV1SEnJwclJSWoq6uDk5MTPD094efnBy8vL5SUlKC6uho6nQ5+fn7w8fGBTqfDqVOncOLECeTn50Ov18PZ2RlBQUGIjIyEQqGA0WjEsWPHUFBQAKPRCK1Wiy5duuDmm2/GhAkTsH37dhw9elQsh4+PD5KTk3HzzTcDQIvfq9XqZsvh4+ODnj17oqCgQJyuvLwcer0ebm5ucHFxQXZ2NmprawEATk5OiIyMxMiRI8V52lo/Hh4eSEpKQq9evaDX68VyFRYWIi8vDw0NDWhqaoJCoYBMJoNcLoezszOcnJzg4eHRbLkAiL9VU1ODHTt2YOfOncjIyEBxcTEMBgNkMhnUajV0Oh18fX3h5uYGg8GA7OxsVFRUwGg0Qi6XQ6PRwN3dHSqVCnl5eairq4PJZBLLEBYWhoiICNTX1yMvLw96vR4mkwkymQwuLi5QKpVwcXGBl5cXgMsvPc3Pz0dDQwOMRiOUSiXUajW8vLzQrVs3VFRU4Ny5cygqKoLRaIRarYZWq4W3tzcaGxvR1NQEk8kEpVIJd3d3VFRUoL6+Hs7OzggICICfn5/FNjRnvm6F9VBXVwe5XA69Xo+KigrI5XL4+/ujd+/ecHd3R3V1dbP9IyEhodn+vnr1ahw+fBhyuRwBAQGoqanB8ePHxXUt/BNe+iaXy6FUKiGTyaBUKuHs7AwXFxc4OTlBr9ejqakJKpUKvr6+iIiIQJ8+faBSqSz2V09PT5hMJjzzzDPNljU3Nxc5OTnw9fVFTEwMampqsGXLFvzwww/Izc1FeXk5GhoaAAAKhUIsS1NTE4xGI2QymbhOhw0bhltvvRXHjx/Hr7/+ij/++AOlpaWora0Vt0lTUxNkMpm47YW/hWV1dnaGh4cHvLy84OrqioaGBjQ0NMDFxQWxsbG45ZZb8MgjjyA+Ph5FRUUoKCiAt7c3evTogUmTJqGkpEQ8JvLz88Vt7ufnh/r6epSXl6O4uBiVlZUwGAziMSCsZ6VSCZVKJaZ2l8lkqKmpQX19PYxGI0wmExQKBZydneHu7g6TyYS6ujo0NjbCyckJQUFBiImJgUqlQllZmbg/xMfHIz8/H/v27YNKpYJOp4NKpUJhYSH8/PwwceJEDBgwoNk++OOPPyIrKwsNDQ0wmUzQarUIDw+HUqm0qAs1Gg0KCgqQlpaGvLw81NTUiPu/l5cXoqOj4erqCo1Gg+rqaov9dPjw4XBycrJZRwvl+P7773Hs2DGUlpaK602lUsHV1RXdunXDrbfeCi8vL+Tl5cHT0xP19fU4dOgQTpw4gYqKCphMJri7u8PNzU1c1xcvXhTL2djYKB7nLi4ukMvlMJlMUKlU4v6n1WqhVquh1+tRV1cHAGhsbISbmxv69++Phx9+GBqNBqWlpViyZAl2794t1g8ymQwKhQIhISFwcnJCVVUV6urqxH3QYDCIvwNAPM5CQkIwbtw4VFRU2DwHBAUFYePGjTh//jxqa2uhUqkQFBSEvn37oq6uDnv27EFRUREMBgNUKhW8vLzQt29fBAQEoLCwEJWVlRbzu/nmm3Hy5EkcPHgQhw8fRklJCXr06IFbb70VNTU1WLZsGRoaGuDm5gaj0YizZ8+itrZWrAeSk5MxatQohISE4MUXX0ROTo64HyuVSmg0Gnh5eUEul0Mul4u/O3nyZLHuvVKSzTOj1+vx3XffYePGjThx4oRYSUh0cYiuK8I70m6k49E8QLqahAsn889CUG3NVhnd3d0REhIClUqF9PR0MWjojHKan8QBwNXVFQBgMBjEk19TU1Oby2C9Dq42uVx+xS9KbIm940kmk0GlUkEmk1kERXK5HAqFAo2NjX+pY1Aul8PX1xc1NTViQKlSqeDi4gI/Pz+MGjUKs2bNaleAI8lgJjs7G7Nnz0Z+fv61Lgr9BXV2xXK9sT7BCdm5uQ6J6GpQKpVQKBTQ6/XQarX4/PPPER8f36Z5SLLNzEsvvQS9Xg8PDw94eHjA1dVVfCRkHv0DsPjbHoVC0exza2/wNH8dg73faOl3fX19W5y/PW19s6h5Oc3/FpZZpVLZnK6lF3faKoO9ZTXfDo6Sy+VITU11aDxrrq6urZ6EbZXf1rzsrRtHObKtrNeL8JjOmvU+KozTEW+Jt76eGTFiRLsCmdbK0payWi+vIDQ0tE1lAiC+RsWarfXcWdr7RmB7j2H+SjpiH+zo31GpVOI+1J51bz2NUqlEcHBwm+djzXwZ7J03NBpNi9MBV143Wc/jSt9Ybc3FxcWh8YTlampqQnR0NKZNmwYnJyf861//avNvSjKYOXz4MKqrq1FbW4va2lo0NDSgoqIC1dXVMBqNUCgUYgVtMplavc1m6/ZkY2Nji9OYV4T2fqOlg6+oqAiA/Urb3s5gXlbhFq09Wq3WolzmJ6jWbsk6csPO3d3d5u8Afy6XMPyDDz5o9p018zsCFy9ebPa9dcVufcKVyWTiOrF1ohLa4djattbbSi6X27zVbV7R2KoAtFqt+Le9fch8OutyCm0mrL+z3l62xnGkgnPk5Ojs7NxsmLB+7AUAtvYBa8JymwfK5ut96tSp4t/Wj00EycnJzaaz9dlcfX29xWdhG9paF8J8hN+Mi4trNo5wbArjeHp6it/ZWz9z5syxWz6BrfWu1+ubXVh0RPDQEYGlvUcfjgSJwnFqHbxbXyS29DstEdqKAK3X5bbKbD1NY2OjzTrJnHAhbV5m6/UsbGO1Wi2eN6y3ryOBgEajueIAxLx+E+oTW/ugwNvbG0DL9YzwnfkxJ6wD8+Nt7NixAP5cjttvvx0nTpzA3XffjcrKSpw4caKtiyPNYMbV1RUuLi7iP1dXV6jVari4uIgNjoDmO5StA8Wa8MzWnFwubzZ+a8GA8KjDXkUgaKkBnC3mB7TQoM4e4ZlkS8yXy9GrfaERZUVFhfg71qzXz/Llyy1+09ZvmK/3rKysZt8Lz4TlcrnNO0cmkwmXLl1qNi+Bh4eH3YrWvLxKpbLZ9MJ2FBpPA7bvElhvN+vtLzTytP7e1r5prwzm45qPY+9uivn45s/V7dm4cWOzYUKZ7f2GUHnZu6NnXgahEjU/VgFgw4YNNqc13zZC2az365b2c+vjRNiGQmNOW/MRtkFubm6zcYRlFbaH0OAW+HP9WG/3ZcuWWXy2tf9bB11Ceaz3qdaO6Zbuqjo6D0fGdXQewrY3PwmabxPzfcr8RG5+Qerob5izdbFjb3zzcR0J9Gyd0IWG2sCfdaR12evr66FQKCwCCeuLppKSkmbztp6P0AlCYOs80tq5x5yw/PbuYgJAaWkpgJaDQ2FZzMsr/C3UPWq1WlxG4dwRGxsLk8mE48ePQ6fTtVgOeyTZZmbx4sX47LPPxMZNQi+Ma9UAj4haxnZMf03CHTXzIP1auJK6m228pEvoLdrQ0GDR2/Af//gHZs6c2aZ5STKYAYBPPvkEH330kc27AkQMbB0jk8ng6emJ7t27IyoqCitWrLBYd3/l9fhXLtuN7mr0ZnNychJ7QV1tTk5ODt3lbKuO2Kevdc+uKxEeHo7HHntMfAzVFpINZgS5ublIT0/H+fPnUVFRAVdXV/H2ml6vF2/r+fv7i4+LGhsbodfrERQUBJPJhKqqKuj1ejg5OSEqKgp+fn44c+YM9Ho9srKysHv3bmRnZ6O8vBzA5asZIV9IQkICoqKiEBQUhMLCQly8eBG//vor9u3bh4KCAotbiGq1Gl27dkW/fv3EvAZVVVU4evSoOH8h5wEAsauip6cnIiMjMXDgQAQGBsLJyQkmk8nu75gzf9zl7e2Nbt26YezYsejXrx88PDxw6tQpFBUV4fDhw/jtt9+Ql5eHyspKMT9Dt27dMHLkSGzatAnp6ekWt7yVSiWCgoLg4eGBvLw8lJeXi13thBwOJpMJzs7OFo9pzLuNymQyuLm5ITIyEhMnTsTQoUPFxtE7d+7E119/jdOnT6OkpARNTU1wd3dHVFQUpkyZAnd3dxQWFsJoNMLLywvdu3dHSEgIjh8/ji+++AJ//PEHCgsLAQBubm7o0qULJkyYAHd3d8hkMuTn52PLli3IyckRH5lptVpER0djypQpSE1NRVpaGtatW4cTJ06gqKgIJpMJbm5uiImJwYABA5CWloZDhw6hsrJSbK8lPKqUy+ViLpLJkycjNjYW33//PXbs2IGsrCwx14PQNdbFxQWVlZWoqqoCAHh5eaFHjx4YM2YMXF1dodPpAFy+RX/06FG4ubkhLCwMMplMbL8k7ENr164Vc0FcuHABNTU1kMlk8PDwQHx8PIYMGYKUlBTExcWJ21StVmPdunUAgP3796OkpARGoxGZmZkoKyuzqGSFsgmPRuLi4jB48GBUVlaisrISZ86cwZEjR5Cfn4+KigrxhCNcealUKjFnjPWjHaEdhUajQX19vdgWqra2Vvzs7u6O7t2748EHH0RlZSUWL16Ms2fPitvA29sbycnJGDNmDPz9/bF+/Xrs3LkTe/bsQW5uLi5duoTGxkZoNBrIZDJ89913+OOPP8RjqaGhQczjIpwY1Go1wsLCMHbsWIwdOxYmkwkVFRX49ddfxTpC2I80Gg0CAgKQmpqKLl26YNu2bcjMzERxcTEUCgW8vLwQHh4OX19fnDp1ChcvXkR9fb3FuvDw8EBMTAz69++P2NhYuLq6io83PDw8cP78efzxxx+47bbbUFJSgiNHjuDLL79EeXm5eIx5eXmhS5cuuP/++6HRaPDAAw+gqqoKHh4eMBgMcHFxgU6ng4uLCyoqKsQ7NI2NjWhsbBRzovj5+SEpKQmjRo2Ct7c3qqqqoFKpsHfvXmRkZKC2thZyuVys00pKSsTcKK6urpDJZGK52kKhUCA6Ohp33nknYmNjsX37dpw/fx5RUVGQyWT46aefkJWVJdaVwrrz9PRETEwM+vTpA4PBgMLCQuh0Omg0GigUClRVVeHgwYM4efKkuH21Wi1SU1Nxzz33oGfPnjh27Bh27doFnU4nPpI8ffo0MjIyAACFhYVobGyEQqGATqeDWq1GfX09amtrMXjwYPTv3x/Hjh3DwYMHxXXh4uKCoKAgDB48GMnJyejZsyfS0tKwZs0anDx5EiUlJTCZTNDpdOITh5qaGovjxxFqtRpdunTBgAEDcPLkSYSHh+Nvf/sbAgICUFRUhPLycuh0OmzatAnff/898vLyxG0v5HQSHicJ9XNiYiIyMjJw6tQpcT/38fFBXFwchg4diosXL2L37t3Iz88X5yU8UrNXbjc3N8THx2P69OkYNmzYFTVslnwwY4t55azX6y0a0ZWVlWHdunU4cuQISktL0djYiKqqKlRUVECv14sbUK1Ww83NDVqtFjU1NWKQ4enpCS8vLxiNRuTn56OwsFBMGieTyeDk5AQfHx+o1WrU1dWJOzxwecO6urqiZ8+emDx5spjgq7i4GDKZDD4+PkhKSsLkyZMBAGvXrsWRI0dQVFQEmUwGb29vxMbGihXK3r17ceLECfGE7efnh6CgIFRUVODUqVMoLCwUk64JAUZ9fb0YZMjlcuh0OgwYMAD3338/oqOjUVZWhm+//RZpaWnIz89HTU0NNBoNIiMjcdNNN0Gr1WLnzp04fvy4RcI882RkQqIoITGdn58funXrhh49eohJv4KDg6HX65GRkYHt27cjPT1dDKLMCe0qXFxcYDAYLCp8gZDoytauLCyj0WgUyyrM1zxhmRBANjQ0WOwHwvIolUq4ubmJJznhJGy+rEajEU1NTeL8zJPQCUnehCB4xowZzdrcZGZmYu3atTh+/HizAFWYtzCf4OBguLu7Qy6Xo7KyUtx/hERXAQEBUKvV2LZtG86ePYuVK1fCYDCIlbkQBDrS/kKj0VhsG+F/rVYLd3d3GAwGMblhTk6OGPR5eXlh5MiRGD9+PNRqNbKyshAeHo7ExERx/rW1tUhLS8OyZctw8eJF5ObmWmyn1iiVSkRERKB///4oKCjAwYMHUVVVJSahMz8RtEY4TswT9KlUKnh6ekKr1aK0tBTl5eUwGAxobGyEUqmEr68v+vfvD5lMhoyMDDFhnnlQolAoxIbhQp1j/bvm+6VwdW7rWHBycoKTkxNqamos9lEnJyd4eXnB2dnZYn9wdnaGXC5HWVkZysvLUV9fD71eL14AzJo1C/feey+cnJzw4IMPYvTo0ejXrx82b96Mo0ePIj8/HyUlJWJyRWGfb2pqgpubG1xdXVFUVISioiKbbSmEZIRqtRq1tbXQ6/Xw9/dHcnIy5syZgy5dugAAqqqqxE4Rvr6+uHDhAj7//HPs3r1bvEiy5ubmhpSUFMyfPx+xsbFIS0vD0qVLceTIEfHiB4CYbFAul4sXskIyRWtCvWB+h0SoK4XtGBQUBCcnJ5SWlsLDwwOTJk3CpEmT8MMPP+Ddd9/FhQsXmpXXuj5wdnZGU1OTmJTQnEKhQFBQEBISElBQUIDMzEyx/aNGo0F4eDiio6NRU1MjJoesqqqCTCaDr68vKisrkZuba7E95HI53NzcxDqsoaEBSqUS3t7eSExMxJgxY7Bjxw6kp6ejpKQEer0efn5+GDFiBKZNmwadTod9+/bh888/x8GDBy3qJvNG3OY3DMzXr5AsTxim0+mQlJSEWbNmoVevXlCr1Q619WqJZIOZM2fO4IMPPsDPP/8sXskSkTQ4cjudj5H+GqSwHaRQxs70V22TZqtc9pI6KpVKxMXFYf78+Rg4cGCbf0uSwczu3bvx0EMPSfa5IHWuznqefaNQqVQwGAyIjIzE+fPnr3Vx6C9IqVQ61OWZHHOjB2MAEBkZiaysLMjlcrz66quYOHFim6aXZNfst956Cx4eHvD29oa3tzfc3d3h7+8Pb29vi3fKmP8T2Or/b91NT61WN+vWZt1dzzpXhq3uxi09/xPaP7Smtd+1N56tMpgvk/BYxV5OA6F8tuYr5CJoKV+KdTdv85w49rpmm38/YsQIm8PN2ep6GBwcLLaMt8fW7Uzrro3C4wFH2NsO9rqB29oO5tMI05mPZ10WYRnMt9+V3qYVCLeQbQUy7e226gjzfC3tZWt/Frat9fa40nwt7U1cKGzz1uoYRziyj9rbD68kaWBHXkh2RAI4R1nvH8I6bym/isDNzc2h3zDPNeUo80CmoxPYCczXs9BuTWBv+dvSvduaI/uz8FhKpVKhqqoKzz//PNzd3fHhhx+2+fckGcxkZWWhqqpK/FdbW4uysjJUVVVZNJQy/yewlbvA+jaYeaM/6+kE5t/b+h2gef4Ac0KeBXs7rhBMWM/TvAGu+UFjK6p3dnZu1u5CIFxV2Suj0LDT1nyFaYWyC89/bRGmf/vtt8VhQhsXa0LlajKZcOzYsWbfW1d61ttILpeLDfXsZdHVarU2c/iYrwfhALNVYZsHZba2kfn3jtz2tV4PwksRrae3LouwDOa5SezlJjLnSOUktGOwxV6Fbr4v2tunhMrNXmVvHsCaB2bmJyAhaZ69d7fYyh1zJSdeW9lYhbIJy2Pe9slegGD+klXh+LEul70TSksXLUJKipbY2w/NhztyAjW/ABPab9jS1uDJuv2FwDyvknX5bO1D1sGwrd+zzuUjHH+2cvyY1zfu7u6t3okSLtLMe9hal0FYDvOLJ0cu0qyZt/MDbO871hdo5uvZZDJZfBbuZLdWx7aFvUSqAMS7LkKm5gULFqC4uBgDBgxAVVVVu15VJMnHTGPGjBFbUwOXN2x9fT2USiXKy8vFhl7mhEZc5g3t7GXttdXwrq2rybyxXEvTuri42KyAW5pnRzJfJ/b+tlUOuVzeph3dzc1N7L0jZGi+kme87bnN7ezsbLPBnSNsrQ9b2856G1l/FhqlC4RulO3dN9vyfUeyXh+t/bZWq0Vtba1Dx0R7fh+43MNH6HF4NVzrdgrt3U9s0el0rSbhvFLC48uWODs72wwsHGG93B35KMx63tbdnx1Zts5ka99vT5lcXFzEBuydVZ8InWuEHl5qtRqzZ8/GZ599hnvvvRfr1q1DQEAA1q5d26b5SjKY2bZtG+bPn/+XbPBEdL3ic/2/ho7eDtYnfW5n6iy2LoKEt3sLd+ydnJywdOlS9OnTp23z7ujCXg1jxozBypUrMWDAgA5rJ9DZrvT5/I1CJpNdUTc9pVIp3pYWXm9B9nl6eiI0NBRqtRp33XUXZDIZ7rjjDnTr1k3ski6wd4K7kufqbSE84mrL75l3GwUuPzby8PAQ9wvrl6925ssnhRfYqlQqh/dL867Cfn5+eOmll5CSkgJ/f38EBwfbLa9MJkNAQIDdNiLmbN3FNhcVFdXmlyxar/eOpNVqLZZLyMnS0b/RUrtGtVrtcFsfR+oy4ThrTxr/a6mtx771DQghHxlw+dHxHXfcgS1btrQ5kAEkememo5jnowEgJnpSqVTw9fWFq6srysrKsHnzZqSlpVnkc0lKSsKECRPExwbCyy6ByxXmtm3bsHnzZuTl5cFgMECtViMoKAjjx4/H1KlTxQMlPz8fq1evxsmTJ8VnrcKjC+GA1Wq1iIuLw9SpUxEYGCiWv7q6Gt988w22bNmC/Px8MX+ESqWCTqcTk5K5uLjA19cX/v7+6NWrF2666SbxN4TlrK6uxsaNG8W8N8DlE11iYiJuueUWbN26Fdu2bcOlS5fQ0NAAuVwOLy8vDBw4EK6urmJiNZlMBr1eD5PJBIVCAYVCAV9fX/FgLSkpQVFREfR6PVQqFTw8PODn54c+ffpg4sSJ4rZQq9XNytTY2AgXFxf4+/sjJSUFbm5uYl4f4HKFoNfrkZaWhl9//RUFBQXQ6/XQaDQWSb+EBFdlZWVYs2YN/vjjD5SVlUGlUolJ7m677TZ4eXk12z5CbobIyEj069cP6enpOHbsGPLz88VcNkajEWq1WlxH8fHxGDx4MDQaDTQaDX766SeL9ezj44OEhAT4+PggMzMTeXl5qK+vh6enJ/r164cBAwaI7zJxd3eHq6urmBdJyNdjvh8LSktLsXLlSpw+fVpsTybk+Ljpppvw008/4bvvvoNGo0GvXr3Qq1cvrF+/Hg8//DCcnZ1RXV2NPXv24NChQzhx4oSYkM/FxQVhYWFISUnB3XffDU9PT+zcuRNKpRJ9+vRBVlYW6urqkJaWJuYrEra5Wq2Gr6+v+NI64HLuJyFJW25urpjXSciN0aNHDwQEBKCsrAyHDx9GaWkplEolunfvjrFjx2LTpk0oKChAY2Oj+CjLz88PU6dOxZQpU1BRUYHCwkKoVCokJibCaDTi7NmzkMvlSE9Ph9FohMFgQF5eHv744w8EBQWhtrZWLIter4dSqYS/vz/69++PIUOGwNnZWVwOYR9JS0sTH3O7ubkhKioKo0ePRkBAgLjNL1y4gKamJgQGBiIyMhK9e/fGTz/9hOzsbDHFREBAABISEtCnTx9UV1djx44dMBgMuOmmmxAVFYWwsDDk5eWJiTYDAwMRHR0NmUyG+fPnw9XVVXzkIOSuuummm7Bnzx789NNP4j46d+5cXLx4EZs3b8bx48fR2NgINzc3hIeHIyAgACaTSdzvzOs8nU4HvV6PzMxMbN++HXq9HnFxcfD19UV+fj5Onz6NnJwcMRmpj48Punfvjv79+2Pfvn04c+YMDhw4IOZ0EpKJuri4oLi4GKWlpaiuroZCoYCHhwcSExPx7LPPoqmpCceOHcM333yDgoICFBUVoba2Vsxlk5SUhEGDBmHDhg04cOAA3n33XSQnJ8PV1RUGg0F8h5ZCocCGDRuwfft2FBUVWdSRiYmJmDFjBtzc3FBTUwO5XC4mJ1Sr1YiJicHWrVvxyy+/oLS0FN7e3ggODoZarYa3tzfy8vLg5uaGiRMnokuXLli3bh1OnTol5gXSaDTo2rUrRo8ejZCQELi5uWHTpk04dOgQoqOjMWDAAADAxx9/jPPnz4t3K2pra8XzwOTJk3Ho0CGkp6fj+PHj4noWjhkhUam/vz8SEhIwYMAA9O/fX0xGajQaUVZWJr7jzrqONT//KJVK+Pj4ICIiAiNGjICTkxOysrJQU1Mj5paKjo7Gli1bxP1q48aNaGxsFF/2qVAoUFtbi9LSUjFfjpB8tG/fvujTp4+4X10JyQczVVVVyMrKwsWLF1FdXS1mG21qakJxcbGYNEsmu5xpVqiwSkpK2v08Va1WW5y0bWnpVq1Go4GXlxfKysqavRMlODgYgwcPRk1NDfbu3YvS0lKL+QgnEh8fH2RnZ6O4uFgsh0ajgaurK+rq6mwmoAPst/0YNGgQ+vbtiz/++ANpaWliECYsi06nQ3R0NHQ6HU6cOGHzZWgtcXNzs0j0JpPJxBP2pUuXcOnSJVRWVjbbJkKjuit5pKhSqRAYGIjCwsJ2P49viUwmQ9euXaFSqXD+/PlW33Pj7u6OlJQUDB48GA0NDSgpKcGlS5eQk5NjcVJrrX2MSqUSEyACl7djbGwsFAoFZs6cCS8vL3Tr1g1qtRr33XefmEjL+iV1rVGpVHB3d0d1dXWz9afVasU7BXv37sWlS5fEq2QnJyfU19cjLCwMEydOxODBg1FRUQEPDw+EhIQgPz8fGRkZeOmllzBo0CCEhobiu+++Ey8aHOXs7IzExEQcPHiwWfuj9rDVPsLHx0c8rtpDCDStG2kL60rIuC3Mvz3VckhICGbMmIHz589j37594gVDY2OjGDibJ72bN28e5s6dC+By49DDhw8jMTERv/76K/773//i6NGjYnAoJE8sLy8Xpxfu3AkXTdaE9ajVajFo0CDEx8dj165dyM3NFS+u/vnPf6KyshLBwcFwdnaGXq/H999/j82bN+PYsWOQyWTiydqWmJgYhIaGYseOHQD+rN/M9wGVSgW1Wo2AgAC4u7sjLS3Nocby5sshPAqx9TksLAy9e/dGYGAgDh06hCNHjlxRagghiFOpVCgoKGj2vZOTE9RqNaqqqprtJ56enmIAbms6pVJp0XZNo9Hg5ptvRkxMDNLT0zFw4EAMGDAA3377LTZv3gwAGD58OEaNGoVly5Zhz549zdrhyOVyODk5ISwsDDqdDocOHbK5XDqdDoMGDcLx48eRn58PV1dXdOvWDbNmzRK3T3R0dLt7t0k2mPnmm2+wePFiMWskEV2fNBpNswDR3d0dFRUVV6XhqqP+au/E+avmggkODkZeXl6HNV6+kdhbPwqFAk5OTtf8haGOELJTC3dkzTk5OeFvf/sb5s2b1+bHlJIMZpYuXYp33nlHzCIo9FSyl9KeiNqOJxYiuhrMu9+rVCrceeedePLJJ9s2j84oWGdbuXIlXF1d4e7uDg8PD7i6usLDw0Ns2Cc8BgJaT9AmjGPOfHp741j367cVRXZE42TrBlaO5INwpDGceQ4HW4QcBS0tg3Ueg5aYN2zrqGWwJSQkpF3TOaojGjWaN160ly8FsFwH1uu6Mxvdmj/66EjCdu/MRra2mOf+seVKG49KpRPCX4m9ZJ0tuZJkcq3tc22pyzrC1T4GANs5k65URyRkFNoWJiYmYuHChfD29hZfeNumsrR5ir+AkpIS1NTUiP/0ej2qq6stGheZJ8drrVK2/t68HYK9cayfG9p6Ru/Ic1l7FalQAdtK6NcaR05Cwu3w1pLdtbQMwjpwJHvmAw880Gr5zNdFe0+kQtsAe9qTnbMthAqjpd8x34YttcEwXwfWz+A74nGGvRNKZwVKwvb18PBo13TtHae1d7eZTKZmjQ/NG9q3xpH2OY7sd/ZO1h29PWydaEaPHm3x2ZHs4leiPW3XruSRmfU2sl4Httq4mG8PR7P/Osq8Aby1jsgMDVxuSG4+bWc8gnIkIaMt5hcYJpMJ7733HjIzM5GamoqioiKHc6+Zk2QwEx8fD1dXV+h0Ouh0Ori7u8PZ2RlarRYqlcriTcXm/zvKkcqpo56N2ztpCzteZ9/mt5d+35FATFhPjlRMixYtEv8WevtY64hlba0sV3pAt7ZvCPtFSwejEATaSu7YUfz8/Fodx14ZrcvkyBWxIydc4epX6FXiKEf2iyvdd6zb3dhqeGmPI9vQPCtsW+fT0e1wbJ3Y7WXGtf77SpjvI9f68aUjdbyjFx3t0VJbz9ayzwtaO68VFBQ4tJ6vRfoK87rHZDJBpVKhqakJhYWF0Ov16Nu3b5vnKck2MydPnsTdd9/d5kqRiNqnIxqTtjSPltrn3Chtd0aOHIldu3ZZ9CK8Gsttq8dge3uE/ZUaZEtFezKqK5VKGI3GDt8/hIb1V5NMJoNWq4VcLkd1dTVUKhW+//77Nt0dBSQazAB/5ljZvHmz2B22vYti/sI48zY2QhfvluarUqnEnCrCaxVs7ZRCTweNRiP2xzcn9Ni4knTeLVGpVHBxcUFVVRVCQ0MREBCAS5cuoaqqSsxJIVSeQmKv1t5bYt0l096r3VujVCrh5OQEFxcXNDY2omvXrvjjjz/E7oPA5UcTnp6ecHd3h7u7O86cOYO8vDzxHUqenp647bbb4Ofnh2+++QanTp2Ci4sLtFotnJycUFFRgerqasTFxcHJyQlpaWkA/rz6cnJygre3N26++WbMnj0bS5cuxerVq6FQKMQy6HQ6aDQa6PV6sct8U1NTs1cUCOtCLpeL74upq6tDTU0NFAqFQynGfX19MXfuXNx555148cUXkZ2djenTp4s5OtLS0ixOGkLXaZlMJi6Tp6cnTCaTmAdJ6Cr96KOPoqKiAl988QV0Oh2cnZ1RXFyMp556CufPn0dJSQmqqqrw22+/wcfHx+ZVZGBgIGpqasTuoUJX8aamJgQEBIhXWFqt1u4xIRD2eeE4bGpqgpeXF4YPH44+ffrg2WefFY8tc5MnT8aGDRvE9xOZTCb4+/tj3rx54j71zjvvQKlU4rbbbsPKlSuxatUq/PDDDygrK0N4eDi6deuGe+65B3q9Hk1NTWIOpZbumrm6umLVqlXYsGEDiouLsWXLFuj1ervBh6+vL8rLy8Vjo6UgISQkBEFBQQgMDERJSQkOHTqEsWPHIiAgAD4+PsjKykJ1dTV27dqF8vJyJCcnw8fHB4mJicjJycGqVatszte8p1VbAxXz8YU74bW1taioqBDXlZAvxmQyISoqCmfPnkVjYyOio6Nx/vx5qNXqdtdrwj7k6ekJJycnXLx40eZ4Go0G3bp1Q2FhISorKxEQEIDS0lIUFxe3+uoHJycnNDQ0iGkzampqEBoaiqysLPEx5KVLl8TxgD/XqXlXbXd3d2i1WuTl5aFfv36QyWRITU1FVFQUfvvtN6xevRp1dXVirqt58+ZBJpPB2dkZYWFhWLBgAaqrq8U7QfZei2PvPGKLXC6Hi4sLGhoaxPfTubu74+mnn8b8+fNRV1cHjUaDpKQk7Nu3zyKw9fPzQ1BQEI4ePYrw8HAUFBSI3f2VSiXCwsLQ0NCAyspKFBUVwcXFBQqFQny0a+sCRqVSQaPRWKQPCQgIwPjx4+Hi4oL4+HgMHTq01eVqti2lGsx0pLq6OmRnZ4uVtqenp5h0yNXVFadOncK2bdvEl18FBwdj+PDhMJlMYrKhmpoaeHl5ITg4GJGRkThw4AA2bdqEiooKaDQahISEoFevXhg0aJDYl76oqAhbtmzBL7/8AqPRiF69euGOO+5AZWUljh49iuzsbDFvR2hoKLp3746EhAQx+REAnD17FkePHkVxcbHFS+fkcjkyMjKQn58PjUaDoKAgJCUl4fDhw+jXr59Ysfj6+orzLC0ttdkgdf369fjhhx9QVFSEwMBA3HHHHRg0aFCzMhQUFKCyshLOzs5QqVTi44ldu3bh9ttvR1NTE06cOIHMzEyo1WqMHj0aN998s/ibDQ0N2Lp1K/R6PUJDQ5GcnIydO3fCZDKJFcOJEyfg5+eHtLQ0BAQEiEmjRo0ahYaGBqSkpEAul+Oll15CfX09GhoaEBoaisDAQGg0Gtx2220ALgcxZ86cEbe5kPxJeEx5/PhxyOVyJCQkiHmJBg8eLL7vpKioCIWFhVi3bh1GjBiBM2fOwGAwQC6XIzQ0FK6urnB1dUVlZSXy8vJQW1srdp8UTg6lpaUALjeODgsLw9mzZ1FUVIRRo0YhJiYGer0e27dvF5ffvBH14sWLkZiYiIaGBvTo0QMhISH497//LeZZGTp0KPr37y+ObzQasWTJEmRmZmLmzJnIzs7Gvn37cP78efj6+iI4OBj5+fnw8fHB8OHDodFocPjwYWRmZkKr1cJoNMLf3x+XLl3C448/jt9++01M7hcZGYmEhATExcUBABYuXIjHHnsM1dXV4r5ZUlKC6upq6HQ6ODk5oaioCLm5uZg/fz569eqFjRs3Ytu2bVCpVBgwYABCQkJw6tQpeHp6wtXVFStWrEBFRQXi4uLg5uYmtoWLi4tDfX099Ho9srKykJSUhMmTJ4vrLjs7GykpKUhJScHFixfxzTffYOTIkUhISIBcLkdeXh7+85//4PDhw+J6jo2NxdmzZ1FbWyvmbQoKCoKvry9SUlIQEREhrtf33nsPU6ZMQVlZGSIjI3HmzBkUFBRg165d0Ov1iI+PR3JyMhoaGvDtt9+KlbxOp4NcLkdDQwPOnTsHDw8PhIaGIjU1FampqdDpdLj//vsxe/ZspKamir+3cOFCMSlbXFwcDAYDsrOz0dDQAF9fX2RkZGD37t3IyckRj/n4+HgcOXIEOTk5OH36NBoaGuDh4YGRI0eisrISO3fuRFZWFpydndG7d28MGzYM/v7++PTTT1FeXg5XV1f4+flh8uTJiI2NFZOhFRYWYuPGjSgsLMT48ePR0NCAQ4cOYfv27ZDL5YiNjYW3tzeMRiNyc3NRVFSEpqYmsYmAv78/UlNTkZycjHPnziEyMhJarRYNDQ1Yv349CgsLMWbMGFRXV+P06dNijpvffvsNQUFBOH36NJqamhAaGoqEhATMnDnTZnsgo9GIvLw8BAcHo6CgAOvWrcPx48fF5Ix6vV48BrRaLYKDgzF69GixHluyZAlmzJiB119/HfPmzcO7776LH3/8Eb6+vhg5ciRCQ0NRUVGBqKgosR1aQUEBxo0bBxcXFxgMBvzjH//AyJEjMWLECDHhXF1dHX755RcxUV1OTg6amppw5MgRlJSU4LnnnkN+fj5OnDiBY8eOobGxEXfeeSfi4+Oxfv16nD9/HtOmTUN9fT127dqF48ePIzg4GFVVVdBqtejfvz/69euHgwcPYtu2bXjiiScwcOBAi3XzzjvvoF+/fkhMTIRWq8WxY8ewZMkSNDQ0QKvV4l//+he8vLywb98+9O3bFxkZGThy5AguXbqE4uJiKBQKREVFYdCgQVAoFFi+fDnq6+sxbtw4hIeHY/PmzThy5AiMRiO6deuG6OhopKeni8kFhYR+0dHRzbZbW0k6mCkqKhKDiaqqKjErqvBCwfPnzyMnJweXLl0SK1F3d3cYDAbxKvnixYstXqV0Rq4GrVYLf39/nD9/XryrY357NiEhAeXl5Th//rxYBgDibcWEhATU1NRgyJAhOHfuHLKyslBQUID6+npoNBrceeedMBgMWLt2Laqrq8W7PtYvktTpdM2eBXt6eiIoKAheXl4wGAxiRVBVVQWDwSDerZLJZLj99tvF553r169v9qIzFxcXjB07FuvWrRPfLFxbW4vu3bujoKBAzAacnJyMqqoqnDlzRpxWLpeLd7saGhps3gERrjjM2yM4OztjwoQJ+OabbyxeaClMGx0djYqKCpSXlzfbrq1171coFAgKCsKFCxdgMpkwa9YsfPnll83GEa6WnJycoNfrxTsiwrCGhgY4OzujR48eUKlUyMrKQkpKCvbs2YPq6mq4uLigZ8+eOHv2LMrKysTyCJWlp6cn9u7dC5PJhPvuuw/ffPMNwsPDkZaWhkcffVQMkhsaGsRtLGzL9nB2dsb8+fMxatQo3HTTTWISteDgYFy4cMGiIXhUVBROnjyJ6dOn4+zZs0hOThYvBGJjY8Vj0MXFBZs2bUJycjIaGxsREBCAadOm4YUXXmjzG3Otb9O7uLhApVKJt6yF/dZaWFgYcnJyHP6d+Ph4/Pvf/8aSJUvQv39/vP322ygrK4O/vz+SkpKQmZmJrKysNpXdfBnc3NxQUVEBmUwmvjgwJCQEY8eORU1NDY4cOYL09HRxGl9fXxQXFzfbX63vvAQFBSE/P188bs0Tvvn5+aFXr15YuHAh8vLy8MorryAzMxNGo7HFRHhubm7QarW4dOlSi8ul1WrF49P87oJOp8OQIUMwZ84ceHt749ChQ9iwYQOSk5Ph5OSETz/9VAz8fH19IZfLUVhYKE4vXLRptVrxjqS3tzcSEhJw5swZmEwmeHp6wtPTE8eOHUN5eTlcXFxw991348MPP7RYR8IxKZfLER0djdOnT4vlF+4aurq6oqqqCm5ubrjnnnuwePFicRzzuzXmlEolFAqFxXdTp05FQkIC3nnnHZvNJMzXUdeuXREaGoqCggJUVVXh1VdfRWxsLG655RaUl5fDZDKhS5cu6NGjBzZs2GAxHycnJzzzzDN45ZVXxLuaMpkMgwYNwsWLF2EwGKDT6ZCZmYnu3bvD398fVVVVuHTpEoKDgxEUFIT169dj5syZWLVqlUUySntPD6zvHgllF84RJpMJ9fX10Gq1CAsLQ0FBAeRyOb744gsxmKmtrcXx48cRGhqKoKAg2zuVHZIMZmprazFjxgycPHnS4pGQVNwobQA6gq1HOIJr/dZiqbvWb/r9K+nIx7ttOb69vLzEO3QdpT3J+zozwZ6bm5v4qonWdHTiQUeXS6p1svnrC9rTA+hqGTRoEPbu3St+Nr+D5uzsjGXLlmHGjBlYt24dJk6cKN6FbwtJ9mZ65ZVXxAUdM2aMeMUhFVI8aK6VlnpVdWYgI6X9qb0YyPypI9upCXdbHdHRgQzQvt5PnZkpuLKy0uFehB3dc8vR5boWdXJH1DFCO6x2dWXuxFw31vM2D2TM2+SEhoaKNyfM6/P2bA9JBjM//PCDuCPs2bMHwOUVJLS9uFpv8TXXUmIuRxL3dSR7+UPslaG9ZWtLroS/OuvyXq3Kra0t9q8Gf39/i883QmDX0axPyubt3BzRWqI/gfAIuqX5d1RCuGnTpnXIfBwltTdIt5WjdUxnHX+deTFoPm/r8gvL3dTUhAsXLlgMmzFjhs1pHCHJYMZ8RQl/NzU14bXXXmv2fWexXtnCc1tbrvZrFsyjdPOEdvbK0N6yCS+btJWHpLUkYe3aWW1cSbR1PvbezOroFaH5slovY3tekGbekFrQlmXqjKsr6xwrjuwfVyuj6ZVkEW7PNMHBwa2O48j2spdXxF6gYZ7or6ULA+G7lpJFXslLD+2V6Wpo6a6Ko8FeR+moi7P2ZDFuS/38V7zwaKn8Qr17zz33AIDY+7M9JBnMCI0QhTeyCpYtWwbg6lxV28oQ3JG/21Enh87o5m3NVqUzZMgQi8/u7u4Wn9tTOdgKUtuyzl1cXK74ubJ5cGj9CMxgMLT5YPz222+bDWvLMtlaJx1doYWHh7c6Trdu3VodR0iUeCX7trCvtefRcnsucswbadr7vfa+5RdwLNDo3bu33e+6du161dp7fPfdd53+G+asOxSYc/TxUUfVo/Yudtpaj7XncV5b9vMr2Q/Me+m15/v2EII74TGUVqttf4qVDivVVfTCCy+IVzSFhYXi8F9//fVaFUlsTd/SoxfgcoXuSHQuhYatSqUSSqXSZnr6w4cPWzzusk7EZH1Qmz+KUygU4pWXUFm4uLg0u6sSGhqKadOmYdy4cfDx8UFUVJTNcgq9Ierq6uzmAGrthCSUzTy3i602J/YSOTpaqTpScbW2/1hXBkJOi5bKFBISYvcdQ9nZ2a2WKSMjQ0whYI8Q/LVl3zbP8yNwcXGBs7Nzq5Wen5+fzccvoaGhDm8P87Ye9raNsFxyuRxOTk5Qq9UICQmxSHPgyHaNi4uDs7Nzs7IdOHCg2bjCPmAwGNCnTx+LY836BHvnnXeKvy9M155HT629r87WMKFHInDlgYVSqRTrCfN13tJdYOt9zVaZw8LCbB5TjmwzW/WJWq22G+QolUrEx8c3+43ExES7v2FvP+/VqxfkcjlkMplYfqEHVXsI3fNt0Wq1uHDhQrsvlIQymdfzSqUSKSkpAIDTp09DJpPhnXfeaffdGUn2ZhKY51gxz2Ph7e2N8vJylJSU4OTJk7h06RK0Wi2io6PFyqKpqQm+vr7w8PBAYmIihg0bhtOnT2PHjh345ZdfxIyEv/32G2prayGTyaDT6fD000+jqqoK3377LcrKyiCTyeDn54fnnnsOtbW1iIiIwMyZMy1u1cvlcjz11FNisqDNmzdDq9WitLQUhw4dgkKhgEajQVVVFYYMGYKJEyciJycHX3/9NRobG/HEE0/A2dkZBQUFOHDgAOLi4rB+/Xox34l5JkilUonExEQx+ZnA09MTH374IdatW4cLFy6I+Uyys7NRWFiI9PR01NTUwNXVFTNmzEB2dja2bdsG4PJdlfr6eqjVajEB3euvvw6lUolXX30VhYWFYvfn8PBwZGVlIS4uDgMHDsSOHTvEro7mwYoQzHh5eWHkyJFwc3ODUqnEkSNHcN999yEuLg5PPfUUDhw4IOYZWbVqldgVWqfTYdmyZRaVwIoVK7Bjxw64uLggOzsb586dE7+TyWRwd3fHyJEjMXv2bCxbtgwGgwEymQwajQaFhYViwiwvLy9cvHgRmZmZ8PPzw4ULF3Dq1CmLSsXFxQUBAQEoKSmxmepcJpOhR48eiI+Px4wZM3Ds2DEcOHAA586dw4kTJ5pleRUOcuHk3b9/fzz44IOorq7G5s2bkZmZiaioKIwYMQLjx4/HJ598gi1btkCr1UKv14tdJzMyMjBkyBCcPXsWJSUlaGxsRI8ePfDpp5/ioYceEk+MarUacXFxYgLAe++9F3PmzEFWVhZ27tyJt956y2awplQq4erq2ixo8/Pzw6uvvgoA2L9/PzIzM5GcnIyKigps3LgRtbW18PPzg7e3N9LS0ixOAuY9TuRyOSIiIrBkyRLx2P7++++RkZHh8BWbi4sLJk2ahBdffBFr165Feno6Tp06hQsXLuDTTz9FbW2t2JPrxIkT+PLLL5GTk4MePXpg9OjRWLlypc0u1v7+/khISEBOTg5qa2vh5OQkplkIDw/HmDFj8NtvvyEhIQGBgYE4d+4campqsGDBAri4uEAul4s5kRYsWIBNmzbhww8/FNezeSoB4PIxO2zYMHh5eeHgwYNISUlBbGwsXF1dcejQIezbtw/jx4/HfffdJyY8bGpqEl/zMmjQIPz0009466238MQTT+Ds2bOYM2cO3nrrrXY9enJ3d8fgwYMxYMAA7Ny5E/v37xfv/CoUCoSHhyMnJ0fsGdbQ0ID58+dj2bJlKC8vF4dPmzZNzMcjdBlviUKhwD333AMnJyd88cUXkMvlYo4Y4Zi555578OOPP6K2tlbMPfP0009j0aJFOH78OA4cOID9+/fjk08+QWZmpsXxJ+yLgYGBeP7557FhwwYoFAo89dRTeOmll9DY2Ijff//doVe8pKam4pNPPkFxcTHuv/9+FBcXN3sE6O/vj5EjR8LT0xNGoxEbNmxAXl4egoKCsHDhQrz//vs4deqUGKTIZDI0NDSIPTs9PT1RXl4unsdMJpP41mnzLvXOzs7o2rUrtFotAgICMHPmTOj1epw5cwb79+9Hnz59cPLkSWzbts3iIk2oi8LDw1FaWorKykr87W9/E3MhHThwQDz+t27dirvuugv19fXYtGmTmNfrmWeewcMPP2yx3IMHD0ZWVhZyc3MtfsvJyQn/93//h+DgYEyaNAnV1dXIyMho8ysNJB3MtIfJZMKFCxcQGBgo5jBZvXo1NBoNhg0bBp1Oh+3bt+Ps2bNQKpUoKirCb7/9Bp1Oh6CgIISEhMDHxwfJyclISEgQ5zd//nzMmjULXbp0wenTp3H06FEYDAYolUqLl5TpdDro9XrMnTsXW7duRXp6Oo4fP46mpiYkJSXh9ttvR1BQkJhRFQBycnKwZs0acYefOnUqQkNDxYylhw8fhl6vR2JiIry8vGA0GsWEe3l5eYiIiEBycjI2b96MV155Bf7+/qipqUFtbS0MBoN4kn/66afFLL5yuRw5OTk4duwYTp06hd9//x25ubkwGo3o2rUrbr31VnTv3h2rVq1CfHw8/Pz8IJPJsHz5coSHh2PkyJEYPHgwAODo0aNYu3YtTp8+LZ4kjEYjnJ2dxbwFUVFRuPnmmzF+/Hjs3r0ber0eQ4YMgbOzM7Zu3Yp3330Xo0ePxoABAxAUFCTmoti1axdUKhW0Wi2Ki4vFoCsuLg6TJ0/G77//jszMTJSUlIhJ7QIDAzFw4EBMmzYNwcHB4uvmk5KSoFQqodfr8fXXX+PYsWNwc3ODRqNBXV0dDAYDysrKMG7cOOTn56OgoABZWVlQKBTo3bs3fHx8oNfrxQBi8+bN2Llzp1hRhIaGIj4+HpMmTYKfnx9yc3PFoPrIkSNiQHvy5En88ssv4v4TGhqK3r17o7q6GocPH0ZRURFkMhl8fX0xevRopKamwt/fHy+88AJOnTqFV199VXzs8//+3//DqFGjxIohNzcXdXV1iIqKwowZMzB27FgMHDgQMTExqKiowJQpUzBx4kT8/vvv8PHxgVKpREZGBkpLS+Hk5ITAwED4+vrixIkTuHTpEpRKJdzd3TFgwAD06tULW7ZsQWFhIVxdXTFgwAAMGzYMly5dwpAhQ8S7B3V1dfjuu++Qn5+PnJwc/PTTT+IjBSGPjpD4Lj8/HxUVFaipqRGzKNfV1SEwMBDBwcHIzc2FUqmEn58fJk6ciMTERHh4eODixYvIycmBr68vunbtih9//BHA5bscp0+fxqVLl+Dp6SkmLxP2eyH/T1xcHPbu3Yvdu3dDrVbj5ZdfRk5ODn7++Wfk5+eLuTpUKhX8/Pzg7u6OwMBAxMXFwdPTE//9739RVFQEuVwu7udCEF9XVwcvLy/0798fSUlJ+PLLL3HhwgUEBAQgPz8f3t7emDt3Lo4ePYrMzEwx59K0adOwa9cuAJfvpBUVFeHgwYOora1FQEAARo4ciaKiIhw5cgSFhYWora0VfycqKgoDBgxAaGgoTp8+jWXLlkGlUiEqKgpdunTBzz//jNDQUPj6+qKiogKxsbH49ddfERwcLObrSkxMxOjRo8WGuXV1dWJixZqaGhQXF0OpVOLChQtitnMnJydkZmYiOjoaKSkpiIyMFPfdmJgYAMCOHTvw22+/4YEHHoBMJkN6ejoyMjJQXV0tZnbXarViZvJvv/1WrB8iIyORnJwsPoprampCfn4+3Nzc8P333+PMmTNobGxE79698eOPPyIgIADZ2dmoq6tDVVUVlEqlmNUWuBxMu7u7w8vLC3q9HiqVCvHx8ejVqxdeffVVTJkyBY2NjTh+/Lh4TAjHrfmj1kuXLiEjIwNVVVWorKzE0KFDMXr0aKjValy8eBEFBQUoKipCZWUlKioq4Ovri6qqKjQ2NsLHx0fc5tHR0Rg3bhx0Oh2Ki4vxySefwNnZGSEhIejSpYt4Z8NgMGDXrl1oaGhAWloaioqK8Oyzz4rZqn/88Uc0NDSgrq4OPj4+mDlzJiZPngyFQoGvv/4ahw4dQnp6OiorK6FUKhEcHIzx48fD29sbv/76K86ePQuFQoEzZ84gISFBzAGzYsUKDBgwQDwue/bsiS5dusDLywuHDh0Sk2umpqbimWeegVwux5dffolz587B29sbU6dORZ8+fa74vA5IPJgpKytDZmYmAgMDcenSJTz55JPo1asXsrKyxCyLp06dEq/6rNPtmyd0Emg0GtTX14tXC9Z5CpRKpZi+28/PD3q9vsVnuwIPDw8EBgaisLAQJSUlzfIpaLVa1NXViRVqWFgYKisr0dDQIN4BMk9rbf6c3M3NDcOGDUNhYSGOHDkiXi2p1Wp4eXmhvr4eFRUVDl3Zuri4iAmWhHZAarXaIuK3lfvFPOeLt7c3SkpK4OLiIt41ANr+3g8XFxfIZDLU1dVZlL0t+WWUSqX4GgdbzHOt+Pr64sEHH8Trr7/u8BvPrdepo3kyZDIZHnnkEWi1WqxevRrnzp0Tl8s6uZjBYBCvpB3NmyGcZM1Tv/v7+6Nv3774/vvvodPpmnUL7si8M9bbyDyxnRCg5eXltXiHQC6XQ6PR2H3Xj0wmQ2xsLM6dOye+TsDWO25aylXkqCvJf9La/tqW9e7IK0Na2keERI6+vr5oaGhARUWF+Fg3MTERR44cafWlikL6fRcXF3Efsrd+zIdbHy/BwcEIDw+HTCZDTk4OvLy80NTUhIKCAhQXFzt8jPv4+MBoNOKzzz6DTqfDLbfc0mLZhTsZtuZvLwGeNT8/P/Tu3RvHjx8Xk2gK9VVr3dCFVws4snxCeYOCglBQUIDQ0FAxkAYu71tDhgxB3759UVxcjHvvvVfsVNCnTx8cOnSoxVdzmB8btvYbPz+/Nm2L1o4TmUyGyMhIeHp64vz586iursaKFStQX1+PZcuWoampCbfccgvuuOMOh37PYt5SDGZWrFiBixcvYsWKFZJoW0KXSTUxFf35iPBqbT97+4qQzVpqzJeHx8Ffg/mJ19/fv01vSm/vNG3V1kBcyBwtFSqVCkFBQSguLsbYsWMhl8uxYcMGzJ8/H3PmzGnTvCQZzHTr1g0qlUq8DWgymTo16VNn6MwKzdE3117LSrUtvx0aGmrxnJWILLV096cj7kxR23RmUPFXD4aFO/OOEPbbBx98EI8//jgAYO3atVi6dCm2bt3apt+VZG+m22+/HY2NjeLtzo7OGnk1dMTO2KVLF5vDHe2ObS/nCtBxibbsaW35zXtnMJDpOPZ6K5jrrG2v0Wg6Zb5tZa/nWmu9xAYMGNAZxWmRo71HWrpD7UggY+sFs9bluFq5hAQdkdulo9IUtHXZ7QUy9noMmhs9enSL33fEuaMz89E4EsgI9buw33700UcYP348Vq9ejZ49eyIvL6/NvyvJOzPA5Ze+CXdmXFxcWn3OC/w130VzraPsG/39Rley/jvjvTotuVr7b2e9p6ezy+/otgwODrZoS9TW6a814aWHV5NMJkNQUJDN9eYoR9ujtJVQh9mqy9q7L1vvCx21bwwZMgT79+9HY2PjNd/XbK0be8upUqkwZswYbNy4scV5Xun5RKPRwGg0wtPTE7t3727TtJK8MwNcbs0vdKurqakRG+YmJibajaJbqkiFK1ahYZsjWopuHb0Ktd5x2pMh0h5Hrib+SoGM+fo0z0vQma6kQrEVyHTG1atwNWe9/zq6blrLxmxN6A7akRQKhdgV3h7r1yi0lfm8W8obZO+EbL4vWN8VuJLEeB1FqKM6I5CZMWOGRd1jfQfBZDI5/OjAno4OZIRtJJTbVl3W3rv2tpKiXimFQoE9e/bAYDC0Or+25lqZPn16s2Gt3WG1dZfI+vgU5tHY2GgRyMTFxdmcp3VyVEcoFApERERgxIgReP311+Hh4WEzM3prJBvMjBs3Dr1790ZMTIyYtM1kMuGFF17AuHHj2lwZC49munTpgu+//14cHhkZaTFeeHi4GDjdddddACxv3QuVXlxcHHx8fMSNK5RHJpNBrVbD2dkZCoUCbm5uFoml2nMVYe/RQXsCFUdPxkLXQet3Cwl5dxxlvp3MD3DhTbBPPvkkUlJS4Obm1qbEc/369cOhQ4fw888/o2fPni2OK8zX2dnZoffBmFcCQu4dga3phfnbq1xsnSiFLqdardZuhexIBSuTycQee+bJtYSulUlJSdDpdHBxcUFQUBCUSiUGDx6MiRMniuUWtpGQoEtgvh6EfdDeNhKWwbzMGo3G4jc8PT2hUCggl8uh0+mQmpoKb29vzJs3z+Y+bn2MC/u7j48PevfuDZ1OBzc3N/Tr16/ZcWxrPuYXMeY9cGQyGW6++WZMmjRJ/N7NzU1MkKlUKqHT6SzK09q+qlar4ebmJmbw7dKlCxISEizSOAiEE5vQyxC4vL5vueWWVi9+HK0H//e//1nUPbb2OXuPr728vKBQKNr0WKg9Qb+w/1qfMFt6jGbrGHF1dbVIxiiTyRAQENCmsgjl12q1GDNmjEMncVvr1DrJau/evREdHY0xY8ZY1CUKhQIuLi7o3r27zXn/8ssvzYa1FjxaN6QPCgoSu7gL60ZohGu+HkNCQsQXPVvvX0L+G6D5Nhb2j3vvvVc8nsPDw/Hcc8/h9ttvx+7duzFv3jyEh4djwYIFLZbdFsk+ZrKWlpaGQ4cOYeLEiXB3dxdzWezatQtGoxHu7u5ISUlBVFQUAgICYDKZkJWVhczMTPTt2xcBAQFwcnIS25E0Njbi22+/hYuLC0JDQ7Ft2zbMnDkTISEhOHz4ME6cOIHhw4fj4MGDmDBhAvLy8sQujn369EFUVBT69OmDBQsW4L///S/+85//oLGxEX379sW7774Lb29vvPHGG0hLS8Mrr7wCV1dXHDt2DO+++y7S09PFA1ev1+PLL79EY2MjPv/8c8TGxuKhhx5CSUkJnnnmGeTk5OCmm25Cr169sHHjRuzbtw9NTU3w8/ODj48PTp8+Ld7SlMlk8Pf3x5w5czB+/Hi4urri3LlzUKlUUCqVWLJkCXbt2iXu5EKeg/r6eosssOY7sKurK3r37o1//OMfaGpqwtKlS3H06FH06NEDjz32GFasWIHly5c3uw0sl8vh7e2NhoYG1NTUiPkTKioqUFdXB5lMhvr6ekyZMkX8LYPBgJMnT8Lf3x/19fVYuXIl4uLixPwWMTExyM7OhkajwW233dZs/9ixYwe6deuGAwcOYNCgQYiOjsa7775rscxKpRIREREIDAzEQw89hE8//RSnT59GREQEHnnkERw4cACLFy+GwWCAVqsVEyoGBgbi2WefxZYtW7Br1y4xgFAqlejZsydmzZqFvn37Yu7cuUhLSwNw+U7Ee++9hx49eiArKwu7du1CVlYWHn30Ubi5uYm5SVQqFUpKSlBbWwtvb2+cP38eS5cuhYeHB4YMGQJXV1cYDAYUFxfD29sbKSkpWLt2LbZs2YIZM2YgNzcXhYWFuO+++1BWVoZDhw6J++6kSZPQs2dPbNiwAdHR0XjjjTfw2WefYcuWLVCpVHjggQeQnZ3drCJ+7bXXMGHCBDz44IP4+eef8fnnn+Pbb7/FCy+8AHd3d2RmZuLDDz/Ezp07xUpVLpcjPDwc7u7uOHv2LGQyGYYPH45Tp04hIyNDnHdKSgqWLFkCb29vxMXFoV+/figuLkZWVhY0Gg0aGxvh7OyMESNGwNPTE+fOncNTTz2FsWPHWjx6fv311zFo0CA4OTlh7dq1yMjIwNixY1FRUYGIiAjU1NRgz5492LFjh3jMubq6IjAwUMxZM3PmTNx///14/PHH0bNnT3z55Zf46KOPoFKpsGjRImRkZODAgQNYtWqV+P4l4Va9kPphxYoVYnqDwsJCvPPOO8jJyYFSqYRGo8Hs2bMRFhaGkSNHYvPmzUhLS8OMGTPg5eUFT09P1NbWYt26ddBoNPD19UVsbCx8fHygVquRm5uLmpoavPbaazh79ix69OgBV1dXvPjii2IOHZPJhMceewy7d+9GVFSURTJJc97e3hgwYADKy8uh1+tx8OBBiwui8PBw3HvvvRg4cCCcnJxw7NgxzJ07V0znINQxMTExmDlzJnbs2IFDhw7By8sLf/vb37Bu3Tr88ccfAC4HjoMGDcLp06ebZZgWksKZTCZ4eHhg4MCBCAkJwYIFC/DJJ59gxYoVdt91pVQqMXToUDzyyCPIzc3Fzp07UVJSgtTUVPzxxx8oLS3FW2+9hZycHCxcuBDnz5+3uy6EO6+bN29GTU0NfvnlF3z22Wditvfs7GzExcWJuWyEi4+8vDzMnj0b3377LfLz89G3b19Mnz4d3333Hb7++msYjUYxR8yjjz6KZcuWYfXq1aisrIRcLhdTYvj6+sLX1xd1dXV48MEHIZPJcMsttyAzMxOvvvoqMjIy7D5tENIaeHh44JtvvoGXlxcaGxtRUFAgdn9vaGhAWFgYCgsLcfToUVRXV+Obb75BaWkpvvzyS/j7+yM4OBgNDQ0wGAz49ddf8cEHHyA7O9uivgwLCxPTiTg5OUEulyMrKwtarRY///yzeFERERGB1NRUvPPOOzAYDHBxccGOHTvEgE74nZbacrbkuglmzF26dEl86aS16upqnDx5Et26dYNOp4PRaER5eTkqKytRWVmJu+++GwcPHhR3rNraWsTHxyMrK0scv7i4GDNnzsTKlSuRlJSEjIwMqFQq8fvCwkLEx8fj/PnzYjI3b29vsYIbOHAgBg4ciOeeew7Tp0/Hhg0bUFdXhzNnziA+Ph4Gg0FMbjVp0iRs2rQJZ86cQb9+/TBv3jy88sorKC4uxqRJk7BkyRKkpqZi3rx5eO2116DX61FWVoaGhgasWrUKu3fvxpdffgkPDw8MHToU//nPf9CtWzc8+eST+Mc//oG33npLnN/06dORmJiIhQsXQqlUwtPTU4yua2pqUFlZicLCQkyePBmRkZEwGAx477330K1bN/To0QPp6em4+eabERkZiZqaGnz88cdYvnw5Nm7cCB8fH3z00Ufo2bMnMjMzUVZWhrq6OjFYamxsFHfm1157DRcuXMCqVatQX1+PW2+9FRcvXkRDQwOOHj2KqKgo9OvXD76+vvj4449x6dIl1NTUwGQyYdy4cSgsLBSX791338XChQsREBCAsLAwzJkzB99++y3ee+893HXXXaitrcXhw4cxaNAg/O9//xNPFvfcc49FGXr37o39+/dDp9OhrKwMvXv3RmlpKU6fPg2DwYBHHnkEy5cvF7M5l5aWokuXLsjMzISHhwdWrVqFhoYGbNu2DcHBwfjss8/Qt29f7N27F+Xl5fDw8ICLiwvy8/NRVFQEhUKBgIAAaLVazJo1CytWrEBcXBxKSkowb948/POf/8TFixexYMECvP/+++jatau4D1RUVCAvLw///Oc/8eWXXyI/Px+FhYWoqKiAWq2GTqcTs7EWFRWJiRNlMhk8PDyQlZWFsLAweHl5wcXFBWq1Gl27dkXPnj3xyy+/4OjRowgLC0N0dDQefPBBfPXVV9izZw9CQkLg6uqKYcOGiZmytVotIiMjUVVVhREjRiAjIwN33XUXXnrpJYSEhCA/Px9vvvkmFi1aBL1ej8zMTPj7+4u//fPPPyM+Ph51dXVISEjAoEGD8Oabb0KtVouJul588UXcdNNNeO2118TKNz09HZMmTcL//vc/DBkyBOvXr8drr72G7du3w9PTExs2bMDAgQNRXV0NrVaLgwcPIjc3F126dMGJEyfEXCS1tbXw9fWFs7MzcnNzERQUJPaevOuuu/D1118jLCwMR44cES+GampqUF5eDldXVzGJY3x8PNRqNY4fP44+ffrghx9+EAP6Hj16ICEhAXv27EFaWhq6d++OCRMmoKCgAJGRkSgsLMTevXtRUlKC6OhoBAcHY/Xq1eId4oSEBMyYMQOlpaX473//KybFe+GFFwBAvNMVGBgId3d3fPPNN+jTpw9Onz4NrVaLGTNmwNnZGRs3bkRmZia0Wi2SkpKQm5uL+vp66HQ6ZGRkICwsDEVFRQgKCkJAQAC8vb2xceNGdO/eHWfOnIFcLsejjz6KuLg4bNy4ES+99BJWrVqF/fv3ixcuM2fOxMcff4zo6Gjs3bsXt9xyCxISEvDss8+KyQ9TUlIwatQoHD9+HPv370d+fj5MJhPKysrg5uaG8vJydOvWDU5OTsjOzkZ9fT3c3d0xZ84cuLu7Y+fOnThz5gzS09Oh0Wjw0Ucf4eTJk/j8889RXV2NkpISjB07FnfddRdyc3PxxhtviMFRQEAAwsPDodVqsXXrVnTr1k3MlaXT6ZCeng4XFxd4eXkhLy8P48ePR1ZWFrKyshAYGIjIyEh06dIFBoMBW7ZsQXh4OE6fPo3p06fjxx9/hKenJ3JycuDn54esrCz4+/ujpKQETU1N6NOnD+6++25cunQJn376KaZNm4bc3Fy4uLhg2rRpePHFF3HixAkEBQWJCUHz8vLg5OSEqqoqMcBevHgxjh8/Dp1Oh5kzZ+L222/H2bNn8d5772Hv3r0YNWoUXnnlFYvzpVCfTJ8+HStWrEBlZSWSk5Px3HPP4Z133kF0dDRUKhUOHDiA5ORkbN26VbyIFLLqT5gwAb1798ann36K3NxcMXli//79ERERgdLSUuzduxfOzs4oKioSk/IBwN1334333ntPrMM0Gg0WLVrUpvP+dRnMnDx5EhMnTmw2/K+0qMLJxFZyMXvllMlkGDZsGH766adm4y5fvlx886igpcZYQiPCDRs2iHcxhMyc5u+7ag/znCQbNmzAxIkTLV5hYO5KkpG1JDo6GmfPnm3WSLezGre2JioqChEREdi1axfWrVuHiRMntnt/XLRoERYuXGgxTCaTYcmSJZg7d6447Go0GLaV96W1RoDCNhf2X0e3ifWxMWnSJKxbtw5A5zUulSph/7cm1DvtadBqPo0jDT2Tk5Nx5MgRi2G2phOGSTGHkK+vr927RO0RHR2NefPm4dFHH7UYLlws2iOsQ1vd8CMjI3HhwgU0NTWJdW1sbCyWLl0KPz8/7NixQ3z1gPV+Yd7F/EoangcGBopBqUCr1cLJyQkKhQJLly4Vj+eJEydCJpOJj7IcJclgZseOHTh27BiysrJQWFiI8vJy1NTUoL6+XnyZYGd31+6oXkBXkgNCqJiupDzWWZAdmc+QIUPw888/QyaT2RxXeIVDaWmpeEJ1JPdAR/YmceREaZ6RuCODHFvr0HzZzLebI65mAGb9W/b2h7YuA/BncCXs88IJVwqBSEtBt/m2tbet2hJYtuUCx145WmMdODjyRnl782/P/hkREdHs/VfOzs5wdnZud36Wzrowamn+jiZDbMu2aU+vLFvbz16vPfPfER6VC8vV0u+0pfdmWy+kBg4ciH379mHq1KlYs2bNjRPMdOvW7S91l4XoenW1u58TEcnl8jYHM5LszeTr6wt3d3eb/4REeiRdnd0dW2paWh/mPXA6slu/QMqBjNDeq2vXrp0y/45I6kZ0rfxV6lm5XI7169eL/7e3XJIMZnr06AFPT0+b/5ydnTulUrdmqwtle1xJRWuey8bR3DgtzQOAQ69dFxoJ2hvX1dXVotsjALtvRhXKrVAoEBwcDODyc9rWciTYy50ibBd7XT/t5TJxdXVt8bMttrKmymQym13BzQ/QtmbCte66bb5s5o96Wsvi2pHaU+EIbxUWlv/FF1+0+P7DDz+0OV1bc7wIx7+wDa0fZ9jSnuUR9l3z7SF0ebfWo0cP8e+2BEEajaZZ2Vr7DKDFdARA8xwj1sdLW3I+Wde39sYzH26rjvb29kZISEgLpW55O7W0n1hPJyyTIxl5nZycHLpANj8ntLbPtrW+bm1+1t/LZDKsX7/e7vgymQwajQbx8fEWdW1LdUivXr0cKyws13dL50rz84T5C5Tb8+RFksHMfffdh2nTptn8N3HiRIwYMQJTp061+Dd06FDExcUhPDwcQ4cOxdSpU9GzZ094eHggMjISEydOFCui8PBwPPnkkxY7ujAfIedDWFiYmAfA/HfMpxF2MOH3U1NTmx2ssbGxGDp0KAYMGIDAwEAMGDBA3KHGjx8PAHj44Ycxffp0jBo1CsCfeSe8vb3RvXt33HnnnYiOjkZYWBj8/f2bnYh79uxpsUMJ8wGA+++/3+LkWl1djU8//RSffvopnnzySURGRorlEfL5AJfz/FRXV2PkyJHiMKFCfPDBBxEfHw/gz8r9rrvuErvc/f3vf8eTTz6JhIQE8aB2cXER/3ZyckK/fv1sBh6hoaEAICZVEtaFUDm5u7vDw8NDTOpkfeIQPgcFBSEiIkIcHh4ebpEzR9iO5mUQli8lJQXAnyfLiIgI8TuTyYTHH3/cYrq4uDhER0eLn++//37xVRS33nornnzySQwcOFAM5p588klxmwUEBCAwMBBJSUkAgDvvvBP9+/cXf09Yz2PGjMH06dORnJws/rZSqUR4eDgmTZoEf39/9OzZE2PGjEF4eLhFDgvzilpotyAwr9zM8wfFxMQAsB1U+vv7IygoSFxG4TgIDw+HTqcTc3J4e3tjwoQJ4vdNTU1ingvgcj4LFxcXi2PG3snMfDvfeuutUKlUYlZwYf8WpjXf7oKhQ4fanJfw2z4+Ps2OKyEVQ2xsrDhMr9ejf//+Yl4bYf1UVlaK0996660IDQ1tdkITymWetDAoKEjc54VtYX1cCHlTzI/j22+/HVOnTkViYmKzbSj0ooqMjBR/U6gThBObk5OTeAwMHToUfn5+dl/n4OTkhF69esHV1RXe3t4IDg62mXdFOEFptdpm2yA1NRWjR48W6xhbFyMeHh7w9va2e7FqPY2XlxfCwsIAAAkJCQD+PK61Wi2USqW4TB999JFYl/j7+4vrX6FQwNnZ2eIYF3rg6HQ6i33CvN1X9+7dLQJb63pIOMaE3xHmGRERYTOg6N69O8LCwsScUAJh/xLqVvN6qKXALzw8HF26dEF0dDRuueUW8TcHDRokniOFfcLX1xfA5XpPqMeEOkpYx8K+JyxndHS0uK5VKlWzQEion4XAJSwsDCtWrEBYWBg+/fRTrFixwm7Z7ZFkm5mr5eDBg6itrcWQIUNsfl9bW4u0tDSLOxQHDx7E0aNHERMTY3O62tpaHDx4UOzOZj5/69+znr/5Z+vfMZ/24MGDKCsrE68o+vbtazGt9XxbWs6DBw/iwIEDUKlUuO+++9q0PNbz/uWXX3Dy5EmL+dgrV3vWfVu2ma2yWo+3Zs0ahIeH210vZWVlcHd3t1leW9uupfm1tEy2rFq1CoGBgbjppptsfv/kk0+itLQUn332WZt+S1gOoYGo9f+9e/dGWloaevbsafP/1radrf3p4MGD2Lp1K4YMGSJOL+y3wnr+/vvvcezYMSQkJIgnwosXL6KgoAAPPvggzp49iz179qC2thZffPEFAIhdg4cMGSJ2axe6pH788cc4ePAgVCoVduzYgczMTLEsR48exe+//449e/bg8OHDzbajdfla2o+s93nr7Wa9X7z99tsW5WxpW9nabidOnEBdXV2zixShHJmZmSgtLcWIESNQXV2N2NhYDBkyRPwNvV6Pzz//HMeOHYOzszPefPNNi9+tra3FE088gR07dgC4fJdWWJcPPPBAs2M9KSkJn3zyibguhWWVy+X4/PPPUVZWhvj4eAwfPtyiHD179hR/59NPP7WoXzQaDYqLi5GWloatW7eKvS99fHwQERGBuXPnwmQy2a1TLl68iMDAQFy6dKnZtkhLS8Mvv/yCkpISeHt74+TJk5g1axaGDBmC77//Hj/99BNGjBiBkSNHNqsDrOtC8++stVQP2aozk5KSxGUX5iuXy3HgwAEUFBSguroa2dnZ+OKLLyzq04MHDwIAvvrqK/z00084efKkzd+xpS31sfV+LhxHwOULH6HesD6OAIjH0pViMENERESSJsnHTEREREQCBjNEREQkaQxmiIiISNIYzBDRVbV27VqLXkud5cKFC4iNjW1z8i0ikp7OT8hCRNeV0tJSLF68GLt370ZxcTHc3d3RrVs3PPzww23KRdEWw4cPF1Ozu7i4IDIyEvfffz/GjBljd5rAwED88ssvYpdbIrp+MZghojb5+9//Lr7dPDQ0FCUlJdi/f3+736njqHnz5uH2229HdXU1li9fLubzEfL+mNPr9VCr1WKODCK6vvExExE5rLKyEgcPHsQTTzyB/v37Izg4GAkJCXjggQdw8803A7j8BvcJEyYgKSkJQ4cOxUsvvWTxMlNbtm/fjkmTJiE+Ph4333wzlixZ0uyFd1qtFr6+voiMjMQLL7wAZ2dn7Ny5E8DlOzcffPABnnrqKaSkpOCFF16w+Zjp9OnTeOCBB5CSkoLk5GTMmDEDOTk54vfffPMNxowZg/j4eIwePRorV67sqFVHRJ2Id2aIyGEajQYajQbbt29HUlKSzXTwMpkMzz77LEJCQpCbm4uXX34Zb7zxBl566SWb8zx48CCefvppPPfcc+jduzdycnLw/PPPAwAeeeQRm9MolUoolUqLN/MuW7YMc+fOtTtNQUEBZs2ahb59++KLL76ATqfD4cOHxaBp48aNWLx4MV544QXExcXhxIkTeP7556HRaDBp0qS2rCYiusoYzBCRw5RKJV577TU8//zz+Oqrr9C9e3f07dsXY8eOFd+9dPfdd4vjh4SE4LHH/r/27h8kmTgOA/jzSpCcSQgSEYQgkdSQi4QgQhTk1mDcEBFRgQlSvtqQcUNDThlCWGBohEhQU2NLW9BmNBhJRIG1BxUXeobv1EFvZr3vK/QePJ/t/vzuvuPDj+Oen1heXv4wzGxsbMDn86mBobOzE8FgELFYrGYwKZfL2NnZwePjI5xOp3re6XRienpaPb67u3uzbnd3Fy0tLYjH42qFwmvtAAAkEglEIhEMDw+rc1xdXWF/f59hhug/xzBDRH/E4/FgYGBA/WX58fEx0uk0otEovF4vTk5OsLW1hevrazw9PeHl5QWlUgnPz881C/YKhQJOT0+RTCbVc7XWrK2tYX19HaVSCYIgYGFh4U2dw2flihcXF3A4HDVL+2RZRrFYhCRJ6q4QAFQqlS+VjhLR92KYIaI/1tzcDJfLBZfLhUAgAEmSkEgk0N/fj9nZWYyNjSEUCqG1tRW5XA6SJEFRlJphRpZlzM3NqTsiv7/n1czMDLxeLwRBgNlsflek91kTcb3mY1mWAQArKyuw2+1vrn3UwE5E/w+GGSL6Z11dXTg6OsL5+Tmq1SoikYgaAg4PD+uu7e3txc3NDSwWS937TCbTp/fUY7PZcHBwAEVR3u3OmM1mtLW14fb2FiMjI3/9DiL6HgwzRPRl9/f3CAaDGB0dhc1mg8FgQD6fRzqdxtDQECwWCxRFQTabxeDgIHK5HPb29uo+MxAIwO/3o6OjAx6PBzqdDoVCAZeXlwiFQg2bfXx8HNlsFuFwGD6fD0ajEWdnZ+jr64PVasX8/Dyi0SiMRiPcbjfK5TLy+TweHh4wNTXVsDmIqPEYZojoywwGA+x2OzKZDIrFIiqVCtrb2yGKIvx+P/R6PZaWlpBKpRCPx+FwOBAOh7G4uPjhM91uN5LJJDY3N5FKpdDU1ASr1QpRFBs6u8lkQiaTQSwWw8TEBHQ6HXp6etQf/YmiCL1ej+3tbayurkIQBHR3d2NycrKhcxBR4/2oVqvV7x6CiIiI6G/xyzYiIiLSNIYZIiIi0jSGGSIiItI0hhkiIiLSNIYZIiIi0jSGGSIiItI0hhkiIiLSNIYZIiIi0jSGGSIiItI0hhkiIiLSNIYZIiIi0jSGGSIiItK0X9fHbwr23FE7AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OgoR6lTrKqY"
      },
      "source": [
        "Use SMOTE (Synthetic Minority Oversampling TEchnique) to balance Train Set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SalePrice\n",
            "140000    18\n",
            "135000    14\n",
            "155000    11\n",
            "130000    10\n",
            "115000     9\n",
            "          ..\n",
            "466500     1\n",
            "172400     1\n",
            "76000      1\n",
            "171500     1\n",
            "182000     1\n",
            "Name: count, Length: 573, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tP1JIwXNEsXO"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      2\u001b[0m oversample \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminority\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43moversample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape, X_test\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:364\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    361\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 364\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    365\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[1;32m    366\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTJO6V5zrdnw"
      },
      "source": [
        "Check Train Set Target distribution after resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQdvEvNRG80Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xTTXMayvo6"
      },
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fizLJ_YQ6elb"
      },
      "source": [
        "### Use standard hyperparameters to find most suitable algorithm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kMgswohfKBda"
      },
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXu0Ryeown7N"
      },
      "source": [
        "Quick GridSearch CV - Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "O7eLJcKEKBlQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LogisticRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 2299, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 2299, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 2299, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 2299, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 2299, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan]\n",
            "  warnings.warn(\n",
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for XGBClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502], got [ 34900  37900  39300  40000  52500  55000  55993  60000  61000  64500\n  66500  67000  72500  73000  75500  76500  78000  79000  79900  80000\n  80500  81000  82000  83000  83500  84000  84500  85000  85400  85500\n  86000  87000  88000  89000  89500  90000  91000  91300  91500  92000\n  93000  93500  94000  94500  94750  95000  96500  97000  98000  98300\n  98600  99500 100000 101800 102000 103000 103200 103600 104900 105000\n 105500 106000 107000 107500 108000 108500 109000 109008 109500 109900\n 110000 110500 111000 111250 112000 113000 114500 114504 115000 116000\n 116500 116900 117000 117500 118000 118400 118500 118858 118964 119000\n 119500 119750 120000 120500 121000 121600 122000 122500 122900 123000\n 123500 124000 124500 124900 125000 125500 126000 126175 126500 127000\n 127500 128000 128500 128900 128950 129000 129500 129900 130000 130250\n 130500 131000 131500 132000 132250 132500 133000 133700 133900 134000\n 134432 134500 134800 134900 135000 135500 135750 135960 136500 136900\n 137000 137450 137500 138000 138500 138800 139000 139400 139600 139950\n 140000 140200 141000 141500 142000 142125 142500 142600 143000 143250\n 143500 143750 144000 144152 144900 145000 145250 146000 146500 146800\n 147000 147400 147500 148000 148500 149000 149300 149500 149700 149900\n 150000 150750 150900 151000 151500 152000 153000 153337 153500 153575\n 153900 154000 154300 154500 154900 155000 155835 156000 157000 157500\n 157900 158000 158900 159000 159500 160000 160200 161000 161500 161750\n 162000 162500 162900 163000 163500 163990 164000 164500 164700 165000\n 165150 165400 165500 166000 167000 167240 167500 167900 168000 168500\n 169000 169500 169990 170000 171000 171500 171750 171900 172000 172400\n 172500 172785 173000 173500 173733 173900 174000 174500 174900 175000\n 175500 176000 176432 176485 176500 177000 178000 178400 178740 179000\n 179200 179400 179500 179665 179900 180000 180500 181000 181134 182000\n 183200 183500 184000 184750 185000 185500 185750 185850 186500 186700\n 187000 187100 187500 188000 188700 189000 189950 190000 191000 192000\n 192500 193000 194000 194500 194700 195000 195400 196000 196500 197000\n 197500 197900 198900 199900 200000 200100 201000 202500 202900 203000\n 204000 204750 204900 205000 205950 206000 207000 207500 208300 208500\n 208900 210000 211000 212000 212900 213000 213500 214000 215000 215200\n 216000 216500 217000 217500 218000 219210 219500 220000 221000 221500\n 222000 222500 223000 224000 224900 225000 226000 227000 227680 227875\n 228000 228500 228950 229000 230000 231500 232000 232600 233170 233230\n 234000 235000 235128 236000 236500 237000 237500 238000 239000 239500\n 239686 240000 241000 241500 242000 244000 244400 244600 245500 248000\n 248328 250000 250580 252000 253000 253293 254000 254900 255000 255500\n 255900 256000 256300 257500 258000 259000 259500 260000 261500 262000\n 262500 263435 264132 264561 265900 265979 266500 267000 268000 269500\n 269790 270000 271000 271900 272000 274000 274300 274725 274900 274970\n 275000 275500 277000 278000 280000 281213 283463 285000 287000 289000\n 290000 293077 294000 295000 295493 297000 299800 301500 302000 303477\n 305000 305900 309000 310000 311500 312500 315000 315500 315750 317000\n 318000 318061 319000 320000 325000 325300 326000 328900 333168 335000\n 336000 337000 337500 339750 340000 341000 342643 345000 348000 350000\n 354000 359100 360000 361919 369900 372402 374000 375000 377426 377500\n 380000 381000 383970 394432 394617 395000 395192 402861 410000 423000\n 424870 426000 430000 437154 440000 451950 466500 485000 501837 556581\n 582933 611657 625000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n 504 505 506], got [ 34900  35311  37900  39300  40000  52000  55000  55993  58500  60000\n  61000  62383  64500  66500  67000  68400  72500  73000  75000  75500\n  76000  78000  79000  79900  80000  81000  83000  83500  84500  85000\n  85400  85500  86000  87000  88000  89000  89500  90000  91000  91300\n  91500  92000  93000  93500  94000  94500  95000  96500  97000  97500\n  98000  98300  98600  99500 100000 101800 102000 102776 103000 103600\n 104900 105000 105500 106000 106500 107000 107400 107500 108000 108480\n 109000 109008 109500 109900 110000 110500 111000 111250 112000 112500\n 113000 114500 114504 115000 116000 117000 117500 118000 118400 118500\n 118964 119000 119500 119900 120000 120500 121500 121600 122000 122500\n 122900 123000 123500 124000 124500 124900 125000 125500 126000 126175\n 126500 127000 127500 128000 128500 128900 128950 129000 129500 129900\n 130000 130250 130500 131000 131400 131500 132000 132250 132500 133000\n 133500 133700 133900 134000 134432 134500 134800 134900 135000 135500\n 135900 135960 136500 136900 137000 137500 138000 138500 138800 138887\n 139000 139400 139900 139950 140000 141000 142000 142125 142500 142600\n 143000 143250 143500 143900 144000 144500 144900 145000 145250 146000\n 147000 147400 147500 148000 148500 149000 149300 149500 149700 149900\n 150000 150750 150900 151000 151400 151500 152000 153000 153337 153500\n 153575 153900 154000 154500 154900 155000 155835 156000 156932 157000\n 157500 157900 158000 159000 159434 159500 159895 159950 160000 161000\n 161500 161750 162000 163000 163500 163990 164000 164500 164700 164900\n 165000 165150 165500 166000 167000 167240 167500 167900 168000 168500\n 169000 169500 169900 169990 170000 171000 171750 171900 172400 172500\n 173000 173500 173733 173900 174000 174500 174900 175000 175500 176000\n 176485 176500 177000 177500 178000 178740 179000 179200 179400 179500\n 179540 179600 179665 179900 180000 180500 181000 181134 182000 183000\n 183500 184000 184100 184750 184900 185000 185500 185750 185850 186500\n 186700 187000 187500 188000 188700 189000 189950 190000 191000 192000\n 192140 192500 193000 194000 194500 194700 195000 195400 196000 196500\n 197000 197500 197900 198900 199900 200000 200141 201000 201800 202500\n 202900 203000 204000 204750 205000 205950 206000 206900 207000 207500\n 208300 208900 209500 210000 211000 212000 212900 213500 214000 214500\n 214900 215000 216000 216500 217000 217500 218000 219210 219500 220000\n 221000 221500 222000 222500 223000 223500 224000 224900 225000 226000\n 226700 227000 227680 227875 228000 228500 228950 229000 230000 231500\n 232000 232600 233170 233230 234000 235000 235128 236000 236500 237000\n 239000 239500 239686 239799 240000 241000 241500 242000 244000 244400\n 244600 245000 246578 248000 248328 250000 250580 252000 252678 253293\n 254000 254900 255000 255500 256000 256300 257000 257500 258000 259000\n 259500 260000 260400 261500 262000 262280 262500 263435 264561 265900\n 265979 266000 266500 267000 268000 269500 269790 270000 271000 271900\n 272000 274000 274300 274725 274900 274970 275000 275500 276000 277000\n 278000 279500 280000 281000 281213 284000 285000 286000 287000 287090\n 289000 290000 293077 294000 295000 295493 297000 299800 301500 302000\n 305000 307000 309000 310000 311500 311872 314813 315000 315500 315750\n 318000 318061 320000 325000 325300 325624 326000 328000 328900 335000\n 336000 337500 339750 340000 341000 342643 345000 350000 354000 360000\n 361919 369900 374000 375000 377426 377500 378500 381000 383970 392500\n 394432 395192 402000 410000 423000 424870 426000 437154 440000 446261\n 465000 466500 475000 485000 501837 611657 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499], got [ 35311  39300  40000  52000  52500  55000  55993  58500  60000  61000\n  62383  68400  72500  73000  75000  75500  76000  76500  78000  79000\n  79900  80000  80500  81000  82000  83000  83500  84000  84500  85000\n  85400  85500  86000  87000  88000  89500  90000  91000  91300  91500\n  92000  93000  93500  94000  94500  94750  95000  96500  97000  97500\n  98000  98600  99500 100000 101800 102000 102776 103000 103200 103600\n 104900 105000 106000 106500 107000 107400 107500 108000 108480 108500\n 109000 109008 109500 109900 110000 110500 111000 111250 112000 112500\n 113000 114500 114504 115000 116000 116500 116900 117000 117500 118000\n 118500 118858 118964 119000 119500 119750 119900 120000 120500 121000\n 121500 121600 122000 122500 123000 123500 124000 124500 124900 125000\n 125500 126000 126175 127000 127500 128000 128500 128900 129000 129500\n 129900 130000 130250 130500 131000 131400 131500 132000 132250 132500\n 133000 133500 133700 133900 134000 134500 134900 135000 135500 135750\n 135900 135960 136500 136900 137000 137450 137500 138000 138500 138800\n 138887 139000 139400 139600 139900 139950 140000 140200 141000 141500\n 142000 142125 142500 142600 143000 143250 143500 143750 143900 144000\n 144152 144500 144900 145000 145250 146000 146500 146800 147000 147400\n 147500 148000 148500 149000 149300 149500 149700 149900 150000 150900\n 151000 151400 151500 152000 153000 153500 153575 153900 154000 154300\n 155000 156000 156932 157000 157900 158000 158900 159000 159434 159500\n 159895 159950 160000 160200 161500 161750 162000 162500 162900 163000\n 163500 164000 164500 164900 165000 165400 165500 166000 167000 167240\n 167500 167900 168000 168500 169000 169500 169900 170000 171000 171500\n 172000 172400 172500 172785 173000 173500 173733 174000 174900 175000\n 175500 176000 176432 176485 176500 177000 177500 178000 178400 178740\n 179000 179200 179400 179500 179540 179600 179900 180000 180500 181000\n 181134 183000 183200 183500 184000 184100 184750 184900 185000 185500\n 185750 185850 186500 186700 187000 187100 187500 188000 188700 189000\n 189950 190000 191000 192000 192140 192500 193000 194000 194500 195000\n 196000 196500 197000 197500 197900 198900 199900 200000 200100 200141\n 201000 201800 202500 202900 203000 204000 204900 205000 206000 206900\n 207500 208300 208500 209500 210000 211000 212000 212900 213000 213500\n 214000 214500 214900 215000 215200 216500 217500 218000 219210 219500\n 220000 221000 221500 222000 222500 223500 224000 224900 225000 226000\n 226700 227000 227680 227875 228000 228500 228950 229000 230000 231500\n 232000 232600 235000 235128 236000 236500 237000 237500 238000 239000\n 239500 239799 240000 241000 241500 242000 244000 244400 245000 245500\n 246578 248000 248328 250000 250580 252678 253000 253293 254000 255000\n 255500 255900 256000 256300 257000 259500 260000 260400 262000 262280\n 262500 264132 264561 265979 266000 266500 267000 268000 269500 269790\n 270000 271000 271900 272000 274000 274300 274970 275000 275500 276000\n 277000 278000 279500 280000 281000 281213 283463 284000 285000 286000\n 287000 287090 290000 293077 295000 295493 297000 299800 301500 302000\n 303477 305000 305900 307000 310000 311500 311872 312500 314813 315000\n 315750 317000 318000 318061 319000 320000 325000 325624 326000 328000\n 333168 335000 336000 337000 339750 340000 341000 345000 348000 350000\n 359100 360000 369900 372402 377500 378500 380000 381000 383970 392500\n 394432 394617 395000 395192 402000 402861 424870 430000 440000 446261\n 451950 465000 466500 475000 485000 556581 582933 611657 625000 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502], got [ 34900  35311  37900  52000  52500  55000  55993  58500  60000  61000\n  62383  64500  66500  67000  68400  73000  75000  75500  76000  76500\n  79000  79900  80000  80500  81000  82000  83000  83500  84000  84500\n  85000  85400  86000  87000  88000  89000  89500  90000  91000  91500\n  93000  93500  94750  95000  96500  97000  97500  98000  98300 100000\n 102000 102776 103000 103200 104900 105000 105500 106000 106500 107000\n 107400 107500 108000 108480 108500 109000 109500 109900 110000 110500\n 111250 112000 112500 113000 114500 114504 115000 116000 116500 116900\n 117000 117500 118000 118400 118500 118858 118964 119000 119500 119750\n 119900 120000 120500 121000 121500 121600 122000 122900 123000 123500\n 124000 124500 124900 125000 125500 126000 126175 126500 127000 127500\n 128000 128500 128900 128950 129000 129500 129900 130000 130500 131000\n 131400 131500 132000 132250 132500 133000 133500 133700 133900 134000\n 134432 134800 134900 135000 135500 135750 135900 135960 136500 137000\n 137450 137500 138000 138500 138800 138887 139000 139400 139600 139900\n 139950 140000 140200 141000 141500 142000 142125 142500 142600 143000\n 143250 143500 143750 143900 144000 144152 144500 144900 145000 146000\n 146500 146800 147000 147500 148000 148500 149000 149500 149900 150000\n 150750 150900 151000 151400 151500 152000 153000 153337 153500 153900\n 154000 154300 154500 154900 155000 155835 156000 156932 157000 157500\n 157900 158000 158900 159000 159434 159500 159895 159950 160000 160200\n 161000 161500 161750 162000 162500 162900 163000 163500 163990 164000\n 164500 164700 164900 165000 165150 165400 165500 167000 167240 167500\n 167900 168000 168500 169000 169500 169900 169990 170000 171000 171500\n 171750 171900 172000 172400 172500 172785 173000 173500 173900 174000\n 174500 175000 175500 176000 176432 176500 177000 177500 178000 178400\n 179000 179200 179500 179540 179600 179665 179900 180000 180500 181000\n 182000 183000 183200 184000 184100 184750 184900 185000 185500 185750\n 185850 186500 187000 187100 187500 188000 188700 189000 189950 190000\n 191000 192000 192140 192500 193000 194000 194500 194700 195000 195400\n 196000 196500 197000 197500 197900 198900 199900 200000 200100 200141\n 201000 201800 202500 202900 203000 204000 204750 204900 205000 205950\n 206900 207000 207500 208300 208500 208900 209500 210000 211000 212000\n 212900 213000 213500 214000 214500 214900 215000 215200 216000 217000\n 218000 219500 220000 221000 222000 222500 223000 223500 224000 224900\n 225000 226000 226700 227000 227680 227875 228000 228500 229000 230000\n 231500 232000 233170 233230 234000 235000 236000 236500 237000 237500\n 238000 239000 239686 239799 240000 241000 241500 242000 244000 244600\n 245000 245500 246578 248328 250000 250580 252000 252678 253000 253293\n 254000 254900 255000 255900 256000 257000 257500 258000 259000 260000\n 260400 261500 262280 262500 263435 264132 265900 266000 268000 269500\n 269790 270000 271000 271900 272000 274000 274725 274900 275000 275500\n 276000 277000 278000 279500 280000 281000 281213 283463 284000 285000\n 286000 287000 287090 289000 290000 293077 294000 297000 302000 303477\n 305000 305900 307000 309000 310000 311872 312500 314813 315000 315500\n 317000 318000 319000 320000 325000 325300 325624 326000 328000 328900\n 333168 335000 337000 337500 339750 340000 341000 342643 348000 350000\n 354000 359100 360000 361919 369900 372402 374000 375000 377426 378500\n 380000 392500 394432 394617 395000 402000 402861 410000 423000 426000\n 430000 437154 440000 446261 451950 465000 475000 485000 501837 556581\n 582933 625000 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500], got [ 34900  35311  37900  39300  40000  52000  52500  55000  58500  60000\n  62383  64500  66500  67000  68400  72500  75000  76000  76500  78000\n  79000  79900  80000  80500  81000  82000  83000  84000  84500  85000\n  85500  86000  87000  88000  89000  89500  90000  91000  91300  91500\n  92000  93000  93500  94000  94500  94750  95000  96500  97000  97500\n  98000  98300  98600  99500 100000 101800 102000 102776 103200 103600\n 104900 105000 105500 106000 106500 107000 107400 107500 108000 108480\n 108500 109000 109008 109500 109900 110000 111000 112000 112500 113000\n 114500 115000 116000 116500 116900 117000 117500 118000 118400 118500\n 118858 119000 119500 119750 119900 120000 120500 121000 121500 122000\n 122500 122900 123000 124000 124500 124900 125000 125500 126000 126500\n 127000 127500 128000 128500 128950 129000 129500 129900 130000 130250\n 130500 131000 131400 131500 132000 132500 133000 133500 133900 134000\n 134432 134500 134800 134900 135000 135500 135750 135900 136500 136900\n 137000 137450 137500 138000 138500 138887 139000 139400 139600 139900\n 140000 140200 141000 141500 142000 142500 143000 143500 143750 143900\n 144000 144152 144500 145000 145250 146000 146500 146800 147000 147400\n 148000 148500 149000 149300 149500 149700 149900 150000 150750 151000\n 151400 152000 153000 153337 153500 153575 153900 154000 154300 154500\n 154900 155000 155835 156000 156932 157000 157500 157900 158000 158900\n 159000 159434 159500 159895 159950 160000 160200 161000 161500 162000\n 162500 162900 163000 163500 163990 164000 164500 164700 164900 165000\n 165150 165400 165500 166000 167000 167500 168000 168500 169000 169500\n 169900 169990 170000 171000 171500 171750 171900 172000 172500 172785\n 173000 173733 173900 174000 174500 174900 175000 175500 176000 176432\n 176485 176500 177000 177500 178000 178400 178740 179000 179200 179400\n 179540 179600 179665 179900 180000 180500 181000 181134 182000 183000\n 183200 183500 184000 184100 184900 185000 186500 186700 187000 187100\n 187500 188000 189000 190000 191000 192000 192140 193000 194500 194700\n 195000 195400 196000 196500 197000 197500 197900 200000 200100 200141\n 201000 201800 202500 203000 204000 204750 204900 205000 205950 206000\n 206900 207000 207500 208500 208900 209500 210000 211000 212000 213000\n 213500 214000 214500 214900 215000 215200 216000 216500 217000 217500\n 219210 219500 220000 221000 221500 222000 222500 223000 223500 224000\n 224900 225000 226000 226700 227000 228000 228500 228950 230000 231500\n 232000 232600 233170 233230 234000 235000 235128 236000 236500 237000\n 237500 238000 239000 239500 239686 239799 240000 241500 242000 244000\n 244400 244600 245000 245500 246578 248000 250000 252000 252678 253000\n 254900 255000 255500 255900 256000 256300 257000 257500 258000 259000\n 259500 260000 260400 261500 262000 262280 262500 263435 264132 264561\n 265900 265979 266000 266500 267000 268000 270000 271000 272000 274300\n 274725 274900 274970 275000 276000 277000 278000 279500 280000 281000\n 283463 284000 285000 286000 287000 287090 289000 290000 294000 295000\n 295493 299800 301500 302000 303477 305900 307000 309000 310000 311500\n 311872 312500 314813 315000 315500 315750 317000 318000 318061 319000\n 320000 325000 325300 325624 328000 328900 333168 335000 336000 337000\n 337500 340000 342643 345000 348000 350000 354000 359100 361919 372402\n 374000 375000 377426 377500 378500 380000 381000 383970 392500 394617\n 395000 395192 402000 402861 410000 423000 424870 426000 430000 437154\n 446261 451950 465000 466500 475000 501837 556581 582933 611657 625000\n 755000]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_scorer, recall_score\n\u001b[1;32m      2\u001b[0m search \u001b[38;5;241m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[38;5;241m=\u001b[39mmodels_quick_search, params\u001b[38;5;241m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 3\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m           \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecall_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m           \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[42], line 20\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[key]\n\u001b[1;32m     18\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m     19\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39mverbose, scoring\u001b[38;5;241m=\u001b[39mscoring, )\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_searches[key] \u001b[38;5;241m=\u001b[39m gs\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502], got [ 34900  37900  39300  40000  52500  55000  55993  60000  61000  64500\n  66500  67000  72500  73000  75500  76500  78000  79000  79900  80000\n  80500  81000  82000  83000  83500  84000  84500  85000  85400  85500\n  86000  87000  88000  89000  89500  90000  91000  91300  91500  92000\n  93000  93500  94000  94500  94750  95000  96500  97000  98000  98300\n  98600  99500 100000 101800 102000 103000 103200 103600 104900 105000\n 105500 106000 107000 107500 108000 108500 109000 109008 109500 109900\n 110000 110500 111000 111250 112000 113000 114500 114504 115000 116000\n 116500 116900 117000 117500 118000 118400 118500 118858 118964 119000\n 119500 119750 120000 120500 121000 121600 122000 122500 122900 123000\n 123500 124000 124500 124900 125000 125500 126000 126175 126500 127000\n 127500 128000 128500 128900 128950 129000 129500 129900 130000 130250\n 130500 131000 131500 132000 132250 132500 133000 133700 133900 134000\n 134432 134500 134800 134900 135000 135500 135750 135960 136500 136900\n 137000 137450 137500 138000 138500 138800 139000 139400 139600 139950\n 140000 140200 141000 141500 142000 142125 142500 142600 143000 143250\n 143500 143750 144000 144152 144900 145000 145250 146000 146500 146800\n 147000 147400 147500 148000 148500 149000 149300 149500 149700 149900\n 150000 150750 150900 151000 151500 152000 153000 153337 153500 153575\n 153900 154000 154300 154500 154900 155000 155835 156000 157000 157500\n 157900 158000 158900 159000 159500 160000 160200 161000 161500 161750\n 162000 162500 162900 163000 163500 163990 164000 164500 164700 165000\n 165150 165400 165500 166000 167000 167240 167500 167900 168000 168500\n 169000 169500 169990 170000 171000 171500 171750 171900 172000 172400\n 172500 172785 173000 173500 173733 173900 174000 174500 174900 175000\n 175500 176000 176432 176485 176500 177000 178000 178400 178740 179000\n 179200 179400 179500 179665 179900 180000 180500 181000 181134 182000\n 183200 183500 184000 184750 185000 185500 185750 185850 186500 186700\n 187000 187100 187500 188000 188700 189000 189950 190000 191000 192000\n 192500 193000 194000 194500 194700 195000 195400 196000 196500 197000\n 197500 197900 198900 199900 200000 200100 201000 202500 202900 203000\n 204000 204750 204900 205000 205950 206000 207000 207500 208300 208500\n 208900 210000 211000 212000 212900 213000 213500 214000 215000 215200\n 216000 216500 217000 217500 218000 219210 219500 220000 221000 221500\n 222000 222500 223000 224000 224900 225000 226000 227000 227680 227875\n 228000 228500 228950 229000 230000 231500 232000 232600 233170 233230\n 234000 235000 235128 236000 236500 237000 237500 238000 239000 239500\n 239686 240000 241000 241500 242000 244000 244400 244600 245500 248000\n 248328 250000 250580 252000 253000 253293 254000 254900 255000 255500\n 255900 256000 256300 257500 258000 259000 259500 260000 261500 262000\n 262500 263435 264132 264561 265900 265979 266500 267000 268000 269500\n 269790 270000 271000 271900 272000 274000 274300 274725 274900 274970\n 275000 275500 277000 278000 280000 281213 283463 285000 287000 289000\n 290000 293077 294000 295000 295493 297000 299800 301500 302000 303477\n 305000 305900 309000 310000 311500 312500 315000 315500 315750 317000\n 318000 318061 319000 320000 325000 325300 326000 328900 333168 335000\n 336000 337000 337500 339750 340000 341000 342643 345000 348000 350000\n 354000 359100 360000 361919 369900 372402 374000 375000 377426 377500\n 380000 381000 383970 394432 394617 395000 395192 402861 410000 423000\n 424870 426000 430000 437154 440000 451950 466500 485000 501837 556581\n 582933 611657 625000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n 504 505 506], got [ 34900  35311  37900  39300  40000  52000  55000  55993  58500  60000\n  61000  62383  64500  66500  67000  68400  72500  73000  75000  75500\n  76000  78000  79000  79900  80000  81000  83000  83500  84500  85000\n  85400  85500  86000  87000  88000  89000  89500  90000  91000  91300\n  91500  92000  93000  93500  94000  94500  95000  96500  97000  97500\n  98000  98300  98600  99500 100000 101800 102000 102776 103000 103600\n 104900 105000 105500 106000 106500 107000 107400 107500 108000 108480\n 109000 109008 109500 109900 110000 110500 111000 111250 112000 112500\n 113000 114500 114504 115000 116000 117000 117500 118000 118400 118500\n 118964 119000 119500 119900 120000 120500 121500 121600 122000 122500\n 122900 123000 123500 124000 124500 124900 125000 125500 126000 126175\n 126500 127000 127500 128000 128500 128900 128950 129000 129500 129900\n 130000 130250 130500 131000 131400 131500 132000 132250 132500 133000\n 133500 133700 133900 134000 134432 134500 134800 134900 135000 135500\n 135900 135960 136500 136900 137000 137500 138000 138500 138800 138887\n 139000 139400 139900 139950 140000 141000 142000 142125 142500 142600\n 143000 143250 143500 143900 144000 144500 144900 145000 145250 146000\n 147000 147400 147500 148000 148500 149000 149300 149500 149700 149900\n 150000 150750 150900 151000 151400 151500 152000 153000 153337 153500\n 153575 153900 154000 154500 154900 155000 155835 156000 156932 157000\n 157500 157900 158000 159000 159434 159500 159895 159950 160000 161000\n 161500 161750 162000 163000 163500 163990 164000 164500 164700 164900\n 165000 165150 165500 166000 167000 167240 167500 167900 168000 168500\n 169000 169500 169900 169990 170000 171000 171750 171900 172400 172500\n 173000 173500 173733 173900 174000 174500 174900 175000 175500 176000\n 176485 176500 177000 177500 178000 178740 179000 179200 179400 179500\n 179540 179600 179665 179900 180000 180500 181000 181134 182000 183000\n 183500 184000 184100 184750 184900 185000 185500 185750 185850 186500\n 186700 187000 187500 188000 188700 189000 189950 190000 191000 192000\n 192140 192500 193000 194000 194500 194700 195000 195400 196000 196500\n 197000 197500 197900 198900 199900 200000 200141 201000 201800 202500\n 202900 203000 204000 204750 205000 205950 206000 206900 207000 207500\n 208300 208900 209500 210000 211000 212000 212900 213500 214000 214500\n 214900 215000 216000 216500 217000 217500 218000 219210 219500 220000\n 221000 221500 222000 222500 223000 223500 224000 224900 225000 226000\n 226700 227000 227680 227875 228000 228500 228950 229000 230000 231500\n 232000 232600 233170 233230 234000 235000 235128 236000 236500 237000\n 239000 239500 239686 239799 240000 241000 241500 242000 244000 244400\n 244600 245000 246578 248000 248328 250000 250580 252000 252678 253293\n 254000 254900 255000 255500 256000 256300 257000 257500 258000 259000\n 259500 260000 260400 261500 262000 262280 262500 263435 264561 265900\n 265979 266000 266500 267000 268000 269500 269790 270000 271000 271900\n 272000 274000 274300 274725 274900 274970 275000 275500 276000 277000\n 278000 279500 280000 281000 281213 284000 285000 286000 287000 287090\n 289000 290000 293077 294000 295000 295493 297000 299800 301500 302000\n 305000 307000 309000 310000 311500 311872 314813 315000 315500 315750\n 318000 318061 320000 325000 325300 325624 326000 328000 328900 335000\n 336000 337500 339750 340000 341000 342643 345000 350000 354000 360000\n 361919 369900 374000 375000 377426 377500 378500 381000 383970 392500\n 394432 395192 402000 410000 423000 424870 426000 437154 440000 446261\n 465000 466500 475000 485000 501837 611657 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499], got [ 35311  39300  40000  52000  52500  55000  55993  58500  60000  61000\n  62383  68400  72500  73000  75000  75500  76000  76500  78000  79000\n  79900  80000  80500  81000  82000  83000  83500  84000  84500  85000\n  85400  85500  86000  87000  88000  89500  90000  91000  91300  91500\n  92000  93000  93500  94000  94500  94750  95000  96500  97000  97500\n  98000  98600  99500 100000 101800 102000 102776 103000 103200 103600\n 104900 105000 106000 106500 107000 107400 107500 108000 108480 108500\n 109000 109008 109500 109900 110000 110500 111000 111250 112000 112500\n 113000 114500 114504 115000 116000 116500 116900 117000 117500 118000\n 118500 118858 118964 119000 119500 119750 119900 120000 120500 121000\n 121500 121600 122000 122500 123000 123500 124000 124500 124900 125000\n 125500 126000 126175 127000 127500 128000 128500 128900 129000 129500\n 129900 130000 130250 130500 131000 131400 131500 132000 132250 132500\n 133000 133500 133700 133900 134000 134500 134900 135000 135500 135750\n 135900 135960 136500 136900 137000 137450 137500 138000 138500 138800\n 138887 139000 139400 139600 139900 139950 140000 140200 141000 141500\n 142000 142125 142500 142600 143000 143250 143500 143750 143900 144000\n 144152 144500 144900 145000 145250 146000 146500 146800 147000 147400\n 147500 148000 148500 149000 149300 149500 149700 149900 150000 150900\n 151000 151400 151500 152000 153000 153500 153575 153900 154000 154300\n 155000 156000 156932 157000 157900 158000 158900 159000 159434 159500\n 159895 159950 160000 160200 161500 161750 162000 162500 162900 163000\n 163500 164000 164500 164900 165000 165400 165500 166000 167000 167240\n 167500 167900 168000 168500 169000 169500 169900 170000 171000 171500\n 172000 172400 172500 172785 173000 173500 173733 174000 174900 175000\n 175500 176000 176432 176485 176500 177000 177500 178000 178400 178740\n 179000 179200 179400 179500 179540 179600 179900 180000 180500 181000\n 181134 183000 183200 183500 184000 184100 184750 184900 185000 185500\n 185750 185850 186500 186700 187000 187100 187500 188000 188700 189000\n 189950 190000 191000 192000 192140 192500 193000 194000 194500 195000\n 196000 196500 197000 197500 197900 198900 199900 200000 200100 200141\n 201000 201800 202500 202900 203000 204000 204900 205000 206000 206900\n 207500 208300 208500 209500 210000 211000 212000 212900 213000 213500\n 214000 214500 214900 215000 215200 216500 217500 218000 219210 219500\n 220000 221000 221500 222000 222500 223500 224000 224900 225000 226000\n 226700 227000 227680 227875 228000 228500 228950 229000 230000 231500\n 232000 232600 235000 235128 236000 236500 237000 237500 238000 239000\n 239500 239799 240000 241000 241500 242000 244000 244400 245000 245500\n 246578 248000 248328 250000 250580 252678 253000 253293 254000 255000\n 255500 255900 256000 256300 257000 259500 260000 260400 262000 262280\n 262500 264132 264561 265979 266000 266500 267000 268000 269500 269790\n 270000 271000 271900 272000 274000 274300 274970 275000 275500 276000\n 277000 278000 279500 280000 281000 281213 283463 284000 285000 286000\n 287000 287090 290000 293077 295000 295493 297000 299800 301500 302000\n 303477 305000 305900 307000 310000 311500 311872 312500 314813 315000\n 315750 317000 318000 318061 319000 320000 325000 325624 326000 328000\n 333168 335000 336000 337000 339750 340000 341000 345000 348000 350000\n 359100 360000 369900 372402 377500 378500 380000 381000 383970 392500\n 394432 394617 395000 395192 402000 402861 424870 430000 440000 446261\n 451950 465000 466500 475000 485000 556581 582933 611657 625000 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502], got [ 34900  35311  37900  52000  52500  55000  55993  58500  60000  61000\n  62383  64500  66500  67000  68400  73000  75000  75500  76000  76500\n  79000  79900  80000  80500  81000  82000  83000  83500  84000  84500\n  85000  85400  86000  87000  88000  89000  89500  90000  91000  91500\n  93000  93500  94750  95000  96500  97000  97500  98000  98300 100000\n 102000 102776 103000 103200 104900 105000 105500 106000 106500 107000\n 107400 107500 108000 108480 108500 109000 109500 109900 110000 110500\n 111250 112000 112500 113000 114500 114504 115000 116000 116500 116900\n 117000 117500 118000 118400 118500 118858 118964 119000 119500 119750\n 119900 120000 120500 121000 121500 121600 122000 122900 123000 123500\n 124000 124500 124900 125000 125500 126000 126175 126500 127000 127500\n 128000 128500 128900 128950 129000 129500 129900 130000 130500 131000\n 131400 131500 132000 132250 132500 133000 133500 133700 133900 134000\n 134432 134800 134900 135000 135500 135750 135900 135960 136500 137000\n 137450 137500 138000 138500 138800 138887 139000 139400 139600 139900\n 139950 140000 140200 141000 141500 142000 142125 142500 142600 143000\n 143250 143500 143750 143900 144000 144152 144500 144900 145000 146000\n 146500 146800 147000 147500 148000 148500 149000 149500 149900 150000\n 150750 150900 151000 151400 151500 152000 153000 153337 153500 153900\n 154000 154300 154500 154900 155000 155835 156000 156932 157000 157500\n 157900 158000 158900 159000 159434 159500 159895 159950 160000 160200\n 161000 161500 161750 162000 162500 162900 163000 163500 163990 164000\n 164500 164700 164900 165000 165150 165400 165500 167000 167240 167500\n 167900 168000 168500 169000 169500 169900 169990 170000 171000 171500\n 171750 171900 172000 172400 172500 172785 173000 173500 173900 174000\n 174500 175000 175500 176000 176432 176500 177000 177500 178000 178400\n 179000 179200 179500 179540 179600 179665 179900 180000 180500 181000\n 182000 183000 183200 184000 184100 184750 184900 185000 185500 185750\n 185850 186500 187000 187100 187500 188000 188700 189000 189950 190000\n 191000 192000 192140 192500 193000 194000 194500 194700 195000 195400\n 196000 196500 197000 197500 197900 198900 199900 200000 200100 200141\n 201000 201800 202500 202900 203000 204000 204750 204900 205000 205950\n 206900 207000 207500 208300 208500 208900 209500 210000 211000 212000\n 212900 213000 213500 214000 214500 214900 215000 215200 216000 217000\n 218000 219500 220000 221000 222000 222500 223000 223500 224000 224900\n 225000 226000 226700 227000 227680 227875 228000 228500 229000 230000\n 231500 232000 233170 233230 234000 235000 236000 236500 237000 237500\n 238000 239000 239686 239799 240000 241000 241500 242000 244000 244600\n 245000 245500 246578 248328 250000 250580 252000 252678 253000 253293\n 254000 254900 255000 255900 256000 257000 257500 258000 259000 260000\n 260400 261500 262280 262500 263435 264132 265900 266000 268000 269500\n 269790 270000 271000 271900 272000 274000 274725 274900 275000 275500\n 276000 277000 278000 279500 280000 281000 281213 283463 284000 285000\n 286000 287000 287090 289000 290000 293077 294000 297000 302000 303477\n 305000 305900 307000 309000 310000 311872 312500 314813 315000 315500\n 317000 318000 319000 320000 325000 325300 325624 326000 328000 328900\n 333168 335000 337000 337500 339750 340000 341000 342643 348000 350000\n 354000 359100 360000 361919 369900 372402 374000 375000 377426 378500\n 380000 392500 394432 394617 395000 402000 402861 410000 423000 426000\n 430000 437154 440000 446261 451950 465000 475000 485000 501837 556581\n 582933 625000 755000]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/cistudent/.local/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500], got [ 34900  35311  37900  39300  40000  52000  52500  55000  58500  60000\n  62383  64500  66500  67000  68400  72500  75000  76000  76500  78000\n  79000  79900  80000  80500  81000  82000  83000  84000  84500  85000\n  85500  86000  87000  88000  89000  89500  90000  91000  91300  91500\n  92000  93000  93500  94000  94500  94750  95000  96500  97000  97500\n  98000  98300  98600  99500 100000 101800 102000 102776 103200 103600\n 104900 105000 105500 106000 106500 107000 107400 107500 108000 108480\n 108500 109000 109008 109500 109900 110000 111000 112000 112500 113000\n 114500 115000 116000 116500 116900 117000 117500 118000 118400 118500\n 118858 119000 119500 119750 119900 120000 120500 121000 121500 122000\n 122500 122900 123000 124000 124500 124900 125000 125500 126000 126500\n 127000 127500 128000 128500 128950 129000 129500 129900 130000 130250\n 130500 131000 131400 131500 132000 132500 133000 133500 133900 134000\n 134432 134500 134800 134900 135000 135500 135750 135900 136500 136900\n 137000 137450 137500 138000 138500 138887 139000 139400 139600 139900\n 140000 140200 141000 141500 142000 142500 143000 143500 143750 143900\n 144000 144152 144500 145000 145250 146000 146500 146800 147000 147400\n 148000 148500 149000 149300 149500 149700 149900 150000 150750 151000\n 151400 152000 153000 153337 153500 153575 153900 154000 154300 154500\n 154900 155000 155835 156000 156932 157000 157500 157900 158000 158900\n 159000 159434 159500 159895 159950 160000 160200 161000 161500 162000\n 162500 162900 163000 163500 163990 164000 164500 164700 164900 165000\n 165150 165400 165500 166000 167000 167500 168000 168500 169000 169500\n 169900 169990 170000 171000 171500 171750 171900 172000 172500 172785\n 173000 173733 173900 174000 174500 174900 175000 175500 176000 176432\n 176485 176500 177000 177500 178000 178400 178740 179000 179200 179400\n 179540 179600 179665 179900 180000 180500 181000 181134 182000 183000\n 183200 183500 184000 184100 184900 185000 186500 186700 187000 187100\n 187500 188000 189000 190000 191000 192000 192140 193000 194500 194700\n 195000 195400 196000 196500 197000 197500 197900 200000 200100 200141\n 201000 201800 202500 203000 204000 204750 204900 205000 205950 206000\n 206900 207000 207500 208500 208900 209500 210000 211000 212000 213000\n 213500 214000 214500 214900 215000 215200 216000 216500 217000 217500\n 219210 219500 220000 221000 221500 222000 222500 223000 223500 224000\n 224900 225000 226000 226700 227000 228000 228500 228950 230000 231500\n 232000 232600 233170 233230 234000 235000 235128 236000 236500 237000\n 237500 238000 239000 239500 239686 239799 240000 241500 242000 244000\n 244400 244600 245000 245500 246578 248000 250000 252000 252678 253000\n 254900 255000 255500 255900 256000 256300 257000 257500 258000 259000\n 259500 260000 260400 261500 262000 262280 262500 263435 264132 264561\n 265900 265979 266000 266500 267000 268000 270000 271000 272000 274300\n 274725 274900 274970 275000 276000 277000 278000 279500 280000 281000\n 283463 284000 285000 286000 287000 287090 289000 290000 294000 295000\n 295493 299800 301500 302000 303477 305900 307000 309000 310000 311500\n 311872 312500 314813 315000 315500 315750 317000 318000 318061 319000\n 320000 325000 325300 325624 328000 328900 333168 335000 336000 337000\n 337500 340000 342643 345000 348000 350000 354000 359100 361919 372402\n 374000 375000 377426 377500 378500 380000 381000 383970 392500 394617\n 395000 395192 402000 402861 410000 423000 424870 426000 430000 437154\n 446261 451950 465000 466500 475000 501837 556581 582933 611657 625000\n 755000]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0bkL-IxwnJx"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpFOc7OAKMuz"
      },
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewezVDt46jTJ"
      },
      "source": [
        "### Do an extensive search on the most suitable algorithm to find the best hyperparameter configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1WozH5frBQ9"
      },
      "source": [
        "Define model and parameters, for Extensive Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDT_WMUErBRB"
      },
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"XGBClassifier\":XGBClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "# documentation to help on hyperparameter list: \n",
        "# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
        "\n",
        "# We will not conduct an extensive search, since the focus\n",
        "# is on how to combine all knowledge in an applied project.\n",
        "# In a workplace project, you may spend more time in this step\n",
        "params_search = {\n",
        "    \"XGBClassifier\":{\n",
        "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
        "        'model__max_depth': [3,10,None],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP2Ua0FGrBRC"
      },
      "source": [
        "Extensive GridSearch CV - Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK1s893orBRD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score, make_scorer\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8oVKtHyr-X8"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AFyZ6-pr9tN"
      },
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get best model name programmatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htAXEVFpwiBV"
      },
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDIt27RdKOG8"
      },
      "outputs": [],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAnJQlDlw1FE"
      },
      "source": [
        "Define the best clf pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLotNfy4MKDE"
      },
      "outputs": [],
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgdxKijH6qJS"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n30pl2dowzW3"
      },
      "source": [
        "* With the current model, we can assess with `.features_importances_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XGczhv2uo2C"
      },
      "outputs": [],
      "source": [
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
        "    'Importance': pipeline_clf['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# re-assign best_features order\n",
        "best_features = df_feature_importance['Feature'].to_list()\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtmFP_Ulpnd"
      },
      "source": [
        "## Evaluate Pipeline on Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myG6tDSGan4r"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "\n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print('---  Confusion Matrix  ---')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
        "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
        "          ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print('---  Classification Report  ---')\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpUfEAGlW5aK"
      },
      "source": [
        "Evaluation: We cross check with metrics defined at ML business case\n",
        "* 80% Recall for Churn, on train and test set\n",
        "* 80% Precision for no Churn on train and test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umWjIvGMNLig"
      },
      "outputs": [],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline_clf,\n",
        "                label_map= ['No Churn', 'Churn'] \n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WgttWjtHHOQ"
      },
      "source": [
        "# Step 3: Refit pipeline with best features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCyOyebVHVmA"
      },
      "source": [
        "## Refit ML Pipeline and Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4PpI2sKC5IL"
      },
      "source": [
        "In theory, a pipeline fitted **using only the most important features** should give the same result as the one fitted with **all variables and feature selection**\n",
        "\n",
        "* However, in this project we have a step for feature augmentation, which is to balance the target Train Set using SMOTE().\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km_-hW0f68DP"
      },
      "source": [
        "## Rewrite ML pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBeckIjkCa4k"
      },
      "source": [
        "New Pipeline for DataCleaning And FeatureEngineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc8ptvFiHJmb"
      },
      "outputs": [],
      "source": [
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "    pipeline_base = Pipeline([\n",
        "\n",
        "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                     variables=['InternetService', 'Contract'])),\n",
        "\n",
        "\n",
        "        # we don't need SmartCorrelatedSelection\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGNs9PU16_Ls"
      },
      "source": [
        "## Rewrite ML Pipeline for Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpjmxzTbCXlg"
      },
      "source": [
        "Function for Pipeline optmisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E76QmoMEWA0"
      },
      "outputs": [],
      "source": [
        "# Pipeline Optmization: Model\n",
        "def PipelineClf(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        # no feature selection needed anymore!!! We know which features to use already!\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75hfh3o5GhoU"
      },
      "source": [
        "## Split Train Test Set, considering only with best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6dX0VeKGhod"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['Churn'], axis=1),\n",
        "    df['Churn'],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19a3t6jI6H6"
      },
      "source": [
        "We filter only the most important variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Acb9T_GXjU"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.filter(best_features)\n",
        "X_test = X_test.filter(best_features)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjOcRGheGhof"
      },
      "source": [
        "## Handle Target Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbQda_pcGhof"
      },
      "outputs": [],
      "source": [
        "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
        "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
        "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQxIFw3KGhog"
      },
      "source": [
        "Check Train Set Target distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZQyth-2Ghog"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9FbCbIrGhoh"
      },
      "source": [
        "Use SMOTE to balance Train Set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtbWft5VGhoh"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YozwzI9eGhoh"
      },
      "source": [
        "Check Train Set Target distribution after SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyL99cYMGhoi"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts().plot(kind='bar',title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_WjvD_QIJ_L"
      },
      "source": [
        "## Grid Search CV: Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESkqrySI7N6u"
      },
      "source": [
        "Using the most suitable model from the last section and its best hyperparameter configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fFaXDOIJ_M"
      },
      "source": [
        "We are using the same model from  the last GridCV search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7F0z__h1qSA"
      },
      "outputs": [],
      "source": [
        "models_search   # XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRteBPgd3ldU"
      },
      "source": [
        "And the best parameters from the last GridCV search "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbGNBeZk3V8r"
      },
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlLJP5Ds3rYp"
      },
      "source": [
        "You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bC8RmE-2Mi2"
      },
      "outputs": [],
      "source": [
        "params_search = {'XGBClassifier':  {\n",
        "    'model__learning_rate': [0.01],   # the value should be in []\n",
        "    'model__max_depth': [3]},  # the value should be in []\n",
        "}\n",
        "params_search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrRJNywsIJ_M"
      },
      "source": [
        "GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv5nO6cJP9fX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score, make_scorer\n",
        "quick_search = HyperparameterOptimizationSearch(\n",
        "    models=models_search, params=params_search)\n",
        "quick_search.fit(X_train, y_train,\n",
        "                 scoring=make_scorer(recall_score, pos_label=1),\n",
        "                 n_jobs=-1, cv=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr_Yu9ykIJ_N"
      },
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqIk1g95IJ_N"
      },
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZcP3yXpIJ_O"
      },
      "source": [
        "Define the best clf pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7Qe2jFEIJ_O"
      },
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0, 0]\n",
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXEXWvsb7Su0"
      },
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8UGZ5bnIJ_P"
      },
      "outputs": [],
      "source": [
        "best_features = X_train.columns\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': best_features,\n",
        "    'Importance': pipeline_clf['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQF20xan7VuK"
      },
      "source": [
        "## Evaluate Pipeline on Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation: We cross-check with metrics defined in the ML business case.\n",
        "* 80% Recall for Churn, on train and test set.\n",
        "* 80% Precision for no Churn on train and test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cpCj2lLHxB-"
      },
      "outputs": [],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline_clf,\n",
        "                label_map= ['No Churn', 'Churn'] \n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBVunRgBqIXQ"
      },
      "source": [
        "# Step 4: Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxnlKI5SJcoO"
      },
      "source": [
        "We will generate the following files\n",
        "* Train set\n",
        "* Test set\n",
        "* Data cleaning and Feature Engineering pipeline\n",
        "* Modeling pipeline\n",
        "* features importance plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16bIOgs3J7OD"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/ml_pipeline/predict_churn/{version}'\n",
        "\n",
        "try:\n",
        "    os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e-gC6sa7hpj"
      },
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHZUZKJ5JiKn"
      },
      "source": [
        "* note that the variables **are transformed already** in X_train and the shape is 8266 - after SMOTE was applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc4fzrdTJno1"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qzq7DgVTJnv3"
      },
      "outputs": [],
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzPsdNGX9gtf"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMoT1cJ39g26"
      },
      "outputs": [],
      "source": [
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYatlgsj7pbB"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEKp3-dJJn3p"
      },
      "source": [
        "* note that the variables are transformed already in X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UMg2vPtJqxM"
      },
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz2OqPW6Jqzv"
      },
      "outputs": [],
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pPTVz219xj3"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap7fYYAm9xsj"
      },
      "outputs": [],
      "source": [
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ufHAplN7tdo"
      },
      "source": [
        "## ML Pipelines: Data Cleaning and Feat Eng pipeline and Modelling Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAbbAO2r248W"
      },
      "source": [
        "We will save 2 pipelines: \n",
        "* Both should be used in conjunction to predict Live Data.\n",
        "* To predict on Train Set, Test Set we use only pipeline_clf, since the data is already processed.\n",
        "\n",
        "\n",
        "\n",
        "Pipeline responsible for Data Cleaning and Feature Engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCcAlvoG3CRm"
      },
      "outputs": [],
      "source": [
        "pipeline_data_cleaning_feat_eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaHdCf4HKBLg"
      },
      "outputs": [],
      "source": [
        "joblib.dump(value=pipeline_data_cleaning_feat_eng ,\n",
        "            filename=f\"{file_path}/clf_pipeline_data_cleaning_feat_eng.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-iU6TL3LVI"
      },
      "source": [
        "* Pipeline responsible for Feature Scaling, and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zEBxfvBqI29"
      },
      "outputs": [],
      "source": [
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObL5Iz8tKdsZ"
      },
      "outputs": [],
      "source": [
        "joblib.dump(value=pipeline_clf ,\n",
        "            filename=f\"{file_path}/clf_pipeline_model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqEUyLG27v9N"
      },
      "source": [
        "## Feature Importance plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBiqB55L1Qhk"
      },
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR0taWpn1RuD"
      },
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Good job, you should clear outputs, then run git commands to push files to the repo. Next, move on to Predict Tenure notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Modeling and Evaluation - Predict Customer Churn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
