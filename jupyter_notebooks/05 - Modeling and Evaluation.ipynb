{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c9d1d9",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fc449",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00139024",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53f38c",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6de590",
   "metadata": {},
   "source": [
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* Feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15815cfc",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1435301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "project_root = \"/workspaces/milestone-project-heritage-housing-issues\"\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"Current working directory set to:\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a456358",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3353f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "train_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
    "test_path = \"outputs/datasets/cleaned/TestSetCleaned.csv\"\n",
    "\n",
    "TrainSet = pd.read_csv(train_path)\n",
    "TestSet = pd.read_csv(test_path)\n",
    "\n",
    "print(\"TrainSet:\", TrainSet.shape)\n",
    "print(\"TestSet:\", TestSet.shape)\n",
    "TrainSet.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b6f7b",
   "metadata": {},
   "source": [
    "# ML Pipeline with all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc40449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'])),\n",
    "\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9849a2",
   "metadata": {},
   "source": [
    "# ML Pipeline Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65264e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineClf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bce5b",
   "metadata": {},
   "source": [
    "# Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    TrainSet.drop(['SalePrice'], axis=1),\n",
    "    TrainSet['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a561ff0",
   "metadata": {},
   "source": [
    "# Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f55399",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a5fd8",
   "metadata": {},
   "source": [
    "Use SMOTE to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b68520",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c61a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac53ca",
   "metadata": {},
   "source": [
    "# Grid Search CV - Sklearn\n",
    "Use standard hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LogisticRegression\": {},\n",
    "    \"XGBClassifier\": {},\n",
    "    \"DecisionTreeClassifier\": {},\n",
    "    \"RandomForestClassifier\": {},\n",
    "    \"GradientBoostingClassifier\": {},\n",
    "    \"ExtraTreesClassifier\": {},\n",
    "    \"AdaBoostClassifier\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba8260",
   "metadata": {},
   "source": [
    "Quick GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de686de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=1),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6111ef8",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefad6a",
   "metadata": {},
   "source": [
    "## Do an extensive search on the most suitable algorithm to find the best hyperparameter configuration.\n",
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"XGBClassifier\":XGBClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may spend more time in this step\n",
    "params_search = {\n",
    "    \"XGBClassifier\":{\n",
    "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
    "        'model__max_depth': [3,10,None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda6678",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a26d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, make_scorer\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=1),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c4961",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896ebfa",
   "metadata": {},
   "source": [
    "Get best model name programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa16537",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aa958",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4887f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada09714",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c22095",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5334936",
   "metadata": {},
   "source": [
    "# Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56d085",
   "metadata": {},
   "source": [
    "With the current model, we can assess with .features_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bf805",
   "metadata": {},
   "source": [
    "# Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77667ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf60fe",
   "metadata": {},
   "source": [
    "Evaluation: We cross check with metrics defined at ML business case\n",
    "\n",
    "* 80% Recall for Churn, on train and test set\n",
    "* 80% Precision for no Churn on train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4713c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_clf,\n",
    "                label_map= [...] \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59deea",
   "metadata": {},
   "source": [
    "# Refit pipeline with best features\n",
    "## Refit ML Pipeline and Resampling\n",
    "In theory, a pipeline fitted using only the most important features should give the same result as the one fitted with all variables and feature selection\n",
    "* However, in this project we have a step for feature augmentation, which is to balance the target Train Set using SMOTE().\n",
    "## Rewrite ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09562f61",
   "metadata": {},
   "source": [
    "New Pipeline for DataCleaning And FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['InternetService', 'Contract'])),\n",
    "\n",
    "\n",
    "        # we don't need SmartCorrelatedSelection\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c23a1",
   "metadata": {},
   "source": [
    "# Rewrite ML Pipeline for Modelling\n",
    "Function for Pipeline optmisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675aced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Optmization: Model\n",
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # no feature selection needed anymore!!! We know which features to use already!\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffdf75",
   "metadata": {},
   "source": [
    "# Split Train Test Set, considering only with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ea49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    TrainSet.drop(['SalePrice'], axis=1),\n",
    "    TrainSet['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f55400",
   "metadata": {},
   "source": [
    "We filter only the most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.filter(best_features)\n",
    "X_test = X_test.filter(best_features)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd922b",
   "metadata": {},
   "source": [
    "# Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f0cd92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PipelineDataCleaningAndFeatureEngineering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline_data_cleaning_feat_eng \u001b[38;5;241m=\u001b[39m \u001b[43mPipelineDataCleaningAndFeatureEngineering\u001b[49m()\n\u001b[1;32m      2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pipeline_data_cleaning_feat_eng\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pipeline_data_cleaning_feat_eng\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PipelineDataCleaningAndFeatureEngineering' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821c843",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794956e7",
   "metadata": {},
   "source": [
    "Use SMOTE to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c08688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b2904",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot(kind='bar',title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {'XGBClassifier':  {\n",
    "    'model__learning_rate': [0.01],   # the value should be in []\n",
    "    'model__max_depth': [3]},  # the value should be in []\n",
    "}\n",
    "params_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8900352",
   "metadata": {},
   "source": [
    "# Grid Search CV: Sklearn\n",
    "Using the most suitable model from the last section and its best hyperparameter configuration.\n",
    "\n",
    "We are using the same model from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search   # XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e728eb5",
   "metadata": {},
   "source": [
    "And the best parameters from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ece61",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {'XGBClassifier':  {\n",
    "    'model__learning_rate': [0.01],   # the value should be in []\n",
    "    'model__max_depth': [3]},  # the value should be in []\n",
    "}\n",
    "params_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfcc37",
   "metadata": {},
   "source": [
    "GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, make_scorer\n",
    "quick_search = HyperparameterOptimizationSearch(\n",
    "    models=models_search, params=params_search)\n",
    "quick_search.fit(X_train, y_train,\n",
    "                 scoring=make_scorer(recall_score, pos_label=1),\n",
    "                 n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07eb98",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fd125",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244996fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf93ab5",
   "metadata": {},
   "source": [
    "# Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fa55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = X_train.columns\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': best_features,\n",
    "    'Importance': pipeline_clf['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871687bb",
   "metadata": {},
   "source": [
    "# Evaluate Pipeline on Train and Test Sets\n",
    "Evaluation: We cross-check with metrics defined in the ML business case.\n",
    "\n",
    "80% Recall for Churn, on train and test set.\n",
    "80% Precision for no Churn on train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599dbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_clf,\n",
    "                label_map= [...]  # replace with actual labels, e.g., ['No Churn', 'Churn']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26f5a1",
   "metadata": {},
   "source": [
    "# Push files to Repo\n",
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_churn/{version}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d6ba2",
   "metadata": {},
   "source": [
    "# Train Set\n",
    "note that the variables are transformed already in X_train and the shape is 8266 - after SMOTE was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a44395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()\n",
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
    "y_train\n",
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56867e",
   "metadata": {},
   "source": [
    "# Test Set\n",
    "note that the variables are transformed already in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()\n",
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)\n",
    "y_test\n",
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c0cb6",
   "metadata": {},
   "source": [
    "# ML Pipelines: Data Cleaning and Feat Eng pipeline and Modelling Pipeline\n",
    "We will save 2 pipelines:\n",
    "* Both should be used in conjunction to predict Live Data.\n",
    "* To predict on Train Set, Test Set we use only pipeline_clf, since the data is already processed.\n",
    "Pipeline responsible for Data Cleaning and Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng\n",
    "\n",
    "joblib.dump(value=pipeline_data_cleaning_feat_eng ,\n",
    "            filename=f\"{file_path}/clf_pipeline_data_cleaning_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a81ce",
   "metadata": {},
   "source": [
    "* Pipeline responsible for Feature Scaling and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf\n",
    "\n",
    "joblib.dump(value=pipeline_clf ,\n",
    "            filename=f\"{file_path}/clf_pipeline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28965509",
   "metadata": {},
   "source": [
    "# Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.show()\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
