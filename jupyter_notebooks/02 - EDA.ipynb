{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer Business Requirement 1: ‚ÄúThe client is interested to understand the patterns from the house sales dataset, to learn the most relevant variables that are correlated to house sale prices.‚Äù\n",
        "    * Explore the main patterns in the housing dataset.\n",
        "    * Identify the most relevant variables correlated with house sale prices.\n",
        "    * Generate visualizations to support insights.\n",
        "    * Prepare insights for use in the Streamlit app answering Business Requirement 1.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* `outputs/datasets/collection/house_prices_records.csv`: cleaned and curated dataset with house sale records.\n",
        "* `outputs/datasets/collection/inherited_houses.csv`: dataset containing inherited properties the client owns.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Printed top correlated variables to `SalePrice` using Pearson and Spearman correlation.\n",
        "* Visualizations (scatter plots, box plots) of most correlated features.\n",
        "* Optional parallel plot for multidimensional categorical visualization. \n",
        "\n",
        "## Additional Comments\n",
        "- We decided not to combine the two CSVs, instead analyzed the main dataset (`house_prices_records.csv`) and kept `inherited_houses.csv` for prediction later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the pre-processed datasets from outputs\n",
        "df_main = pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "df_client = pd.read_csv(\"outputs/datasets/collection/inherited_houses.csv\")\n",
        "\n",
        "print(\"üè† Main dataset:\")\n",
        "display(df_main.head())\n",
        "\n",
        "print(\"üèòÔ∏è Inherited properties:\")\n",
        "display(df_client.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df_main, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temporary Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_encoded = df_main.copy()\n",
        "categorical_cols = df_encoded.select_dtypes(include=['object']).columns\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pearson correlation\n",
        "corr_pearson = df_encoded.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:11]\n",
        "print(\"üìä Top Pearson correlations:\\n\", corr_pearson)\n",
        "\n",
        "# Spearman correlation\n",
        "corr_spearman = df_encoded.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:11]\n",
        "print(\"üìä Top Spearman correlations:\\n\", corr_spearman)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine top variables from both methods\n",
        "top_n = 5\n",
        "top_vars = list(set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list()))\n",
        "print(\"Variables to investigate:\", top_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualising Relationships with SalesPrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scatter & Box Plots for Top Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "def plot_categorical(df_main, col, target_var):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.boxplot(data=df_main, x=col, y=target_var)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col} vs {target_var}\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_numerical(df_main, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(data=df_main, x=col, y=target_var)\n",
        "    plt.title(f\"{col} vs {target_var}\")\n",
        "    plt.show()\n",
        "\n",
        "target_var = 'SalePrice'\n",
        "\n",
        "for col in top_vars:\n",
        "    if df_encoded[col].dtype == 'object':\n",
        "        plot_categorical(df_main, col, target_var)\n",
        "    else:\n",
        "        plot_numerical(df_main, col, target_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parallel  Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "\n",
        "# Example for 'OverallQual' binning\n",
        "var_to_bin = 'OverallQual' if 'OverallQual' in df_encoded.columns else top_vars[0]\n",
        "\n",
        "quality_map = [-np.Inf, 4, 6, 8, np.Inf]\n",
        "disc = ArbitraryDiscretiser(binning_dict={var_to_bin: quality_map})\n",
        "df_parallel = disc.fit_transform(df_encoded[top_features + ['SalePrice']].copy())\n",
        "\n",
        "# Rename bins\n",
        "labels_map = {\n",
        "    0: \"<4\", 1: \"4-6\", 2: \"6-8\", 3: \"8+\"\n",
        "}\n",
        "df_parallel[var_to_bin] = df_parallel[var_to_bin].replace(labels_map)\n",
        "\n",
        "fig = px.parallel_categories(df_parallel, color=\"SalePrice\", color_continuous_scale='Viridis')\n",
        "fig.show(renderer='notebook')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps\n",
        "\n",
        "- We identified strong correlations between several numerical features and `SalePrice`, such as `OverallQual`, `GrLivArea`, and `GarageArea`.\n",
        "- Several categorical variables like `Neighborhood`, `KitchenQual`, and `GarageFinish` are likely important but need proper encoding.\n",
        "- We will now move to the **Data Cleaning Notebook**, where we will:\n",
        "  - Handle missing values\n",
        "  - Drop or transform irrelevant or problematic features\n",
        "  - Prepare the dataset for modeling\n",
        "\n",
        "Outputs from this notebook:\n",
        "- A good understanding of variable relationships\n",
        "- `df_main` ready for cleaning and transformation in the next step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    os.makedirs(name='outputs/datasets/cleaned', exist_ok=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Save the combined dataset to be cleaned in the next notebook\n",
        "df_main.to_csv(\"outputs/datasets/cleaned/df_main_for_cleaning.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
